"""
Extracted handler implementations: analytics
Auto-generated by refactor_main.py
"""
import json
import sys
import time
import asyncio
import traceback
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from service_context import get_service_context

from database import db
from error_handler import handle_error, AppError, ErrorType
from service_locator import (
    get_cache_manager,
    get_multi_channel_stats,
    get_user_analytics,
    get_user_tracker,
    member_extraction_service
)
# All handlers receive (self, payload) where self is BackendService instance.
# They are called via: await handler_impl(self, payload)
# Inside, use self.db, self.send_event(), self.telegram_manager, etc.
# This is a transitional pattern - later, replace self.xxx with ctx.xxx

async def handle_get_account_health_report(self, payload: Dict[str, Any]):
    """Handle get-account-health-report command - ç²å–å¸³è™Ÿå¥åº·å ±å‘Š"""
    try:
        if self.message_queue.account_rotator:
            report = self.message_queue.account_rotator.get_account_health_report()
            self.send_event("account-health-report", report)
        else:
            self.send_event("account-health-report", [])
    
    except Exception as e:
        self.send_log(f"Error getting account health report: {str(e)}", "error")

async def handle_get_performance_summary(self):
    """Handle get-performance-summary command"""
    try:
        # ğŸ†• æ€§èƒ½å„ªåŒ–ï¼šä½¿ç”¨ç·©å­˜æ¸›å°‘é »ç¹æŸ¥è©¢
        cache = get_cache_manager()
        cache_key = "performance_summary"
        cached = cache.get("stats", cache_key)  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ  namespace åƒæ•¸
        if cached:
            self.send_event("performance-summary", cached)
            return
        
        from performance_monitor import get_performance_monitor
        monitor = get_performance_monitor()
        if monitor:
            summary = monitor.get_performance_summary()
            # ç·©å­˜ 10 ç§’
            cache.set("stats", cache_key, summary, ttl=10)  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ  namespace åƒæ•¸
            self.send_event("performance-summary", summary)
        else:
            self.send_log("Performance monitor not initialized", "warning")
            self.send_event("performance-summary", {})
    except Exception as e:
        app_error = handle_error(e, {"command": "get-performance-summary"})
        self.send_log(f"Error getting performance summary: {str(app_error)}", "error")
        self.send_event("performance-summary", {})

async def handle_get_performance_metrics(self, payload: Dict[str, Any]):
    """Handle get-performance-metrics command"""
    try:
        # ğŸ†• æ€§èƒ½å„ªåŒ–ï¼šä½¿ç”¨ç·©å­˜
        cache = get_cache_manager()
        limit = payload.get('limit', 100)
        cache_key = f"performance_metrics_{limit}_{payload.get('startTime', '')}_{payload.get('endTime', '')}"
        cached = cache.get("stats", cache_key)  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ  namespace åƒæ•¸
        if cached:
            self.send_event("performance-metrics", cached)
            return
        
        from performance_monitor import get_performance_monitor
        from datetime import datetime
        monitor = get_performance_monitor()
        if monitor:
            # Parse time filters from payload
            start_time = None
            end_time = None
            
            if payload.get('startTime'):
                start_time = datetime.fromisoformat(payload['startTime'].replace('Z', '+00:00'))
            if payload.get('endTime'):
                end_time = datetime.fromisoformat(payload['endTime'].replace('Z', '+00:00'))
            
            # Get metrics history with filters
            metrics = monitor.get_metrics_history(
                start_time=start_time,
                end_time=end_time,
                limit=limit
            )
            
            # Convert datetime objects to ISO strings
            for metric in metrics:
                if 'timestamp' in metric and isinstance(metric['timestamp'], datetime):
                    metric['timestamp'] = metric['timestamp'].isoformat()
            
            result = {"metrics": metrics}
            # ğŸ†• ç·©å­˜ 15 ç§’
            cache.set("stats", cache_key, result, ttl=15)  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ  namespace åƒæ•¸
            self.send_event("performance-metrics", result)
        else:
            self.send_log("Performance monitor not initialized", "warning")
            self.send_event("performance-metrics", {"metrics": []})
    except Exception as e:
        app_error = handle_error(e, {"command": "get-performance-metrics", "payload": payload})
        self.send_log(f"Error getting performance metrics: {str(app_error)}", "error")
        self.send_event("performance-metrics", {"metrics": []})

async def handle_get_sending_stats(self, payload: Dict[str, Any]):
    """Handle get-sending-stats command"""
    try:
        days = payload.get('days', 7)
        phone = payload.get('phone')  # Optional
        
        stats = await db.get_message_sending_stats(days, phone)
        self.send_event("sending-stats", {"stats": stats, "days": days, "phone": phone})
    except Exception as e:
        handle_error(e, {"command": "get-sending-stats", "payload": payload})
        self.send_log(f"Error getting sending stats: {str(e)}", "error")

async def handle_get_account_sending_comparison(self, payload: Dict[str, Any]):
    """Handle get-account-sending-comparison command"""
    try:
        days = payload.get('days', 7)
        
        comparison = await db.get_account_sending_comparison(days)
        self.send_event("account-sending-comparison", {"comparison": comparison, "days": days})
    except Exception as e:
        handle_error(e, {"command": "get-account-sending-comparison", "payload": payload})
        self.send_log(f"Error getting account sending comparison: {str(e)}", "error")

async def handle_get_alerts(self, payload: Dict[str, Any]):
    """Handle get-alerts command"""
    try:
        limit = payload.get('limit', 50)
        level = payload.get('level')  # Optional: 'info', 'warning', 'error', 'critical'
        unresolved_only = payload.get('unresolvedOnly', False)
        
        if unresolved_only:
            alerts = await db.get_unresolved_alerts(limit)
        else:
            alerts = await db.get_recent_alerts(limit, level)
        
        self.send_event("alerts-loaded", {"alerts": alerts, "count": len(alerts)})
    except Exception as e:
        handle_error(e, {"command": "get-alerts", "payload": payload})
        self.send_log(f"Error getting alerts: {str(e)}", "error")

async def handle_acknowledge_alert(self, payload: Dict[str, Any]):
    """Handle acknowledge-alert command"""
    try:
        alert_id = payload.get('alertId')
        if not alert_id:
            self.send_log("Alert ID required", "error")
            return
        
        await db.acknowledge_alert(alert_id)
        self.send_log(f"Alert {alert_id} acknowledged", "success")
        
        # Send updated alerts
        alerts = await db.get_recent_alerts(50)
        self.send_event("alerts-loaded", {"alerts": alerts, "count": len(alerts)})
    except Exception as e:
        handle_error(e, {"command": "acknowledge-alert", "payload": payload})
        self.send_log(f"Error acknowledging alert: {str(e)}", "error")

async def handle_resolve_alert(self, payload: Dict[str, Any]):
    """Handle resolve-alert command"""
    try:
        alert_id = payload.get('alertId')
        if not alert_id:
            self.send_log("Alert ID required", "error")
            return
        
        await db.resolve_alert(alert_id)
        self.send_log(f"Alert {alert_id} resolved", "success")
        
        # Send updated alerts
        alerts = await db.get_recent_alerts(50)
        self.send_event("alerts-loaded", {"alerts": alerts, "count": len(alerts)})
    except Exception as e:
        handle_error(e, {"command": "resolve-alert", "payload": payload})
        self.send_log(f"Error resolving alert: {str(e)}", "error")

async def handle_get_high_value_groups(self, payload: Dict[str, Any]):
    """ç²å–é«˜åƒ¹å€¼ç¾¤çµ„"""
    try:
        tracker = get_user_tracker()
        if not tracker:
            self.send_event("high-value-groups", {"success": False, "error": "ç”¨æˆ¶è¿½è¹¤ç³»çµ±æœªåˆå§‹åŒ–"})
            return
        
        result = await tracker.get_high_value_groups(
            limit=payload.get('limit', 50)
        )
        
        self.send_event("high-value-groups", result)
        
    except Exception as e:
        self.send_event("high-value-groups", {"success": False, "error": str(e)})

async def handle_get_group_overlap_analysis(self, payload: Dict[str, Any]):
    """ç²å–ç¾¤çµ„é‡ç–Šåˆ†æ"""
    try:
        analytics = get_user_analytics()
        if not analytics:
            self.send_event("group-overlap-analysis", {"success": False, "error": "ç”¨æˆ¶åˆ†ææœªåˆå§‹åŒ–"})
            return
        
        result = await analytics.get_group_overlap_analysis(
            min_overlap=payload.get('minOverlap', 2)
        )
        
        self.send_event("group-overlap-analysis", result)
        
    except Exception as e:
        self.send_event("group-overlap-analysis", {"success": False, "error": str(e)})

async def handle_get_unified_overview(self, payload: Dict[str, Any]):
    """ç²å–çµ±ä¸€æ¦‚è¦½"""
    try:
        stats = get_multi_channel_stats()
        if not stats:
            self.send_event("unified-overview", {"success": False, "error": "çµ±è¨ˆç³»çµ±æœªåˆå§‹åŒ–"})
            return
        
        result = await stats.get_unified_overview(
            days=payload.get('days', 7)
        )
        
        self.send_event("unified-overview", result)
        
    except Exception as e:
        self.send_event("unified-overview", {"success": False, "error": str(e)})

async def handle_get_daily_trends(self, payload: Dict[str, Any]):
    """ç²å–æ¯æ—¥è¶¨å‹¢"""
    try:
        stats = get_multi_channel_stats()
        if not stats:
            self.send_event("daily-trends", {"success": False, "error": "çµ±è¨ˆç³»çµ±æœªåˆå§‹åŒ–"})
            return
        
        result = await stats.get_daily_trends(
            days=payload.get('days', 30)
        )
        
        self.send_event("daily-trends", result)
        
    except Exception as e:
        self.send_event("daily-trends", {"success": False, "error": str(e)})

async def handle_get_channel_performance(self, payload: Dict[str, Any]):
    """ç²å–æ¸ é“æ•ˆèƒ½"""
    try:
        stats = get_multi_channel_stats()
        if not stats:
            self.send_event("channel-performance", {"success": False, "error": "çµ±è¨ˆç³»çµ±æœªåˆå§‹åŒ–"})
            return
        
        result = await stats.get_channel_performance()
        
        self.send_event("channel-performance", result)
        
    except Exception as e:
        self.send_event("channel-performance", {"success": False, "error": str(e)})

# ==================== æ•¸æ“šé©…å‹• Handlers (Phase D) ====================

async def handle_analyze_attribution(self, payload: Dict[str, Any]):
    """åˆ†æè½‰åŒ–æ­¸å› """
    try:
        from conversion_attribution import analyze_attribution
        
        result = await analyze_attribution(
            model=payload.get("model", "linear"),
            days=payload.get("days", 30)
        )
        
        self.send_event("attribution-analysis", {
            "success": True,
            **result
        })
    except Exception as e:
        print(f"[Backend] Error analyzing attribution: {e}", file=sys.stderr)
        self.send_event("attribution-analysis", {"success": False, "error": str(e)})

async def handle_analyze_account_roi(self, payload: Dict[str, Any]):
    """åˆ†æå¸³è™Ÿ ROI"""
    try:
        from account_roi import analyze_account_roi
        
        result = await analyze_account_roi(
            rank_by=payload.get("rankBy", "efficiency")
        )
        
        self.send_event("account-roi-analysis", {
            "success": True,
            **result
        })
    except Exception as e:
        print(f"[Backend] Error analyzing account ROI: {e}", file=sys.stderr)
        self.send_event("account-roi-analysis", {"success": False, "error": str(e)})

async def handle_analyze_time_effectiveness(self, payload: Dict[str, Any]):
    """åˆ†ææ™‚æ®µæ•ˆæœ"""
    try:
        from time_analysis import analyze_time_effectiveness
        
        result = await analyze_time_effectiveness()
        
        self.send_event("time-analysis", {
            "success": True,
            **result
        })
    except Exception as e:
        print(f"[Backend] Error analyzing time effectiveness: {e}", file=sys.stderr)
        self.send_event("time-analysis", {"success": False, "error": str(e)})

async def handle_get_group_collected_stats(self, payload: Dict[str, Any]):
    """ğŸ†• ç²å–ç¾¤çµ„å·²æ”¶é›†ç”¨æˆ¶çµ±è¨ˆ"""
    import sys
    print(f"[Backend] handle_get_group_collected_stats: {payload}", file=sys.stderr)
    
    group_id = payload.get('groupId')
    telegram_id = payload.get('telegramId')
    
    try:
        from database import db
        await db.connect()
        
        collected_users = 0
        monitored_messages = 0
        
        if telegram_id:
            telegram_id_str = str(telegram_id)
            # ğŸ”§ ä¿®å¾©ï¼šæŸ¥è©¢ discussion_messages è¡¨ï¼ˆç¾¤çµ„ç›£æ§æ¶ˆæ¯çš„æ­£ç¢ºä½ç½®ï¼‰
            try:
                messages_result = await db.fetch_one(
                    "SELECT COUNT(*) as count FROM discussion_messages WHERE discussion_id = ?",
                    (telegram_id_str,)
                )
                if messages_result:
                    monitored_messages = messages_result['count'] if isinstance(messages_result, dict) else (messages_result[0] if messages_result else 0)
                
                users_result = await db.fetch_one(
                    "SELECT COUNT(DISTINCT user_id) as count FROM discussion_messages WHERE discussion_id = ? AND user_id IS NOT NULL AND user_id != ''",
                    (telegram_id_str,)
                )
                if users_result:
                    collected_users = users_result['count'] if isinstance(users_result, dict) else (users_result[0] if users_result else 0)
                
                print(f"[Backend] Stats from discussion_messages: messages={monitored_messages}, users={collected_users}", file=sys.stderr)
            except Exception as dm_err:
                print(f"[Backend] discussion_messages query failed: {dm_err}, trying collected_users", file=sys.stderr)
            
            # ğŸ†• åŒæ™‚æŸ¥è©¢ collected_users è¡¨ï¼ˆå¾æ­·å²æ¶ˆæ¯æ”¶é›†çš„ç”¨æˆ¶ï¼‰
            try:
                cu_result = await db.fetch_one(
                    "SELECT COUNT(*) as count FROM collected_users WHERE source_group = ? OR source_group = ?",
                    (telegram_id_str, f"-100{telegram_id_str.lstrip('-')}")
                )
                if cu_result:
                    cu_count = cu_result['count'] if isinstance(cu_result, dict) else (cu_result[0] if cu_result else 0)
                    if cu_count > collected_users:
                        collected_users = cu_count
                        print(f"[Backend] Updated collected_users from collected_users table: {collected_users}", file=sys.stderr)
            except Exception:
                pass  # è¡¨å¯èƒ½ä¸å­˜åœ¨
        
        self.send_event("group-collected-stats", {
            "groupId": group_id,
            "collectedUsers": collected_users,
            "monitoredMessages": monitored_messages
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        self.send_event("group-collected-stats", {
            "groupId": group_id,
            "collectedUsers": 0,
            "monitoredMessages": 0,
            "error": str(e)
        })

async def handle_get_history_collection_stats(self, payload: Dict[str, Any]):
    """ğŸ†• ç²å–æ­·å²æ¶ˆæ¯æ”¶é›†çµ±è¨ˆï¼ˆç”¨æ–¼æ”¶é›†å°è©±æ¡†ï¼‰"""
    import sys
    print(f"[Backend] handle_get_history_collection_stats: {payload}", file=sys.stderr)
    
    group_id = payload.get('groupId')
    telegram_id = payload.get('telegramId')
    
    try:
        from database import db
        await db.connect()
        
        chat_id = str(telegram_id) if telegram_id else str(group_id)
        
        # æŸ¥è©¢æ¶ˆæ¯ç¸½æ•¸
        total_messages = 0
        messages_result = await db.fetch_one(
            "SELECT COUNT(*) as count FROM chat_history WHERE chat_id = ?",
            (chat_id,)
        )
        if messages_result:
            total_messages = messages_result['count'] if hasattr(messages_result, '__getitem__') else 0
        
        # æŸ¥è©¢å”¯ä¸€ç™¼é€è€…æ•¸é‡
        unique_senders = 0
        senders_result = await db.fetch_one(
            "SELECT COUNT(DISTINCT sender_id) as count FROM chat_history WHERE chat_id = ? AND sender_id IS NOT NULL AND sender_id != ''",
            (chat_id,)
        )
        if senders_result:
            unique_senders = senders_result['count'] if hasattr(senders_result, '__getitem__') else 0
        
        # æŸ¥è©¢æ´»èºç”¨æˆ¶æ•¸ï¼ˆç™¼è¨€>=3æ¬¡ï¼‰
        active_users = 0
        active_result = await db.fetch_one(
            """SELECT COUNT(*) as count FROM (
                SELECT sender_id, COUNT(*) as msg_count 
                FROM chat_history 
                WHERE chat_id = ? AND sender_id IS NOT NULL AND sender_id != ''
                GROUP BY sender_id 
                HAVING msg_count >= 3
            )""",
            (chat_id,)
        )
        if active_result:
            active_users = active_result['count'] if hasattr(active_result, '__getitem__') else 0
        
        # æŸ¥è©¢æ¶ˆæ¯æ™‚é–“ç¯„åœ
        date_range = {'first': '', 'last': ''}
        date_result = await db.fetch_one(
            "SELECT MIN(timestamp) as first_date, MAX(timestamp) as last_date FROM chat_history WHERE chat_id = ?",
            (chat_id,)
        )
        if date_result:
            date_range['first'] = str(date_result['first_date']) if date_result.get('first_date') else ''
            date_range['last'] = str(date_result['last_date']) if date_result.get('last_date') else ''
        
        # æŸ¥è©¢å·²æ”¶é›†ç”¨æˆ¶æ•¸ï¼ˆåœ¨ collected_users è¡¨ä¸­ï¼‰
        collected_users = 0
        collected_result = await db.fetch_one(
            "SELECT COUNT(*) as count FROM collected_users WHERE source_groups LIKE ?",
            (f'%{chat_id}%',)
        )
        if collected_result:
            collected_users = collected_result['count'] if hasattr(collected_result, '__getitem__') else 0
        
        self.send_event("history-collection-stats", {
            "groupId": group_id,
            "success": True,
            "stats": {
                "totalMessages": total_messages,
                "uniqueSenders": unique_senders,
                "activeUsers": active_users,
                "collectedUsers": collected_users,
                "dateRange": date_range
            }
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        self.send_event("history-collection-stats", {
            "groupId": group_id,
            "success": False,
            "error": str(e)
        })

async def handle_get_group_profile(self, payload: Dict[str, Any]):
    """ç²å–ç¾¤çµ„ç•«åƒ"""
    try:
        chat_id = payload.get('chatId')
        
        if not chat_id:
            raise ValueError("ç¾¤çµ„ ID ä¸èƒ½ç‚ºç©º")
        
        profile = await member_extraction_service.get_group_profile(str(chat_id))
        
        self.send_event("group-profile", {
            "success": True,
            "profile": profile
        })
        
    except Exception as e:
        self.send_event("group-profile", {
            "success": False,
            "error": str(e)
        })

async def handle_compare_groups(self, payload: Dict[str, Any]):
    """æ¯”è¼ƒå¤šå€‹ç¾¤çµ„"""
    try:
        chat_ids = payload.get('chatIds', [])
        
        if len(chat_ids) < 2:
            raise ValueError("è‡³å°‘éœ€è¦å…©å€‹ç¾¤çµ„é€²è¡Œæ¯”è¼ƒ")
        
        profiles = await member_extraction_service.get_group_comparison(chat_ids)
        
        self.send_event("groups-compared", {
            "success": True,
            "profiles": profiles
        })
        
    except Exception as e:
        self.send_event("groups-compared", {
            "success": False,
            "error": str(e)
        })

# ==================== Analytics Handlers ====================

async def handle_analytics_get_stats(self, payload: Dict[str, Any]):
    """ç²å–åˆ†æçµ±è¨ˆæ•¸æ“š"""
    import sys
    from datetime import datetime, timedelta
    
    try:
        period = payload.get('period', 'week')
        print(f"[Backend] Getting analytics stats for period: {period}", file=sys.stderr)
        
        # æ ¹æ“šé€±æœŸè¨ˆç®—æ™‚é–“ç¯„åœ
        now = datetime.now()
        if period == 'today':
            start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
        elif period == 'week':
            start_date = now - timedelta(days=7)
        elif period == 'month':
            start_date = now - timedelta(days=30)
        else:  # quarter
            start_date = now - timedelta(days=90)
        
        # å¾æ•¸æ“šåº«ç²å–çµ±è¨ˆæ•¸æ“š
        result = await db.fetch_one("""
            SELECT 
                COUNT(*) as total_sent,
                SUM(CASE WHEN status = 'replied' THEN 1 ELSE 0 END) as total_replies,
                SUM(CASE WHEN status = 'converted' THEN 1 ELSE 0 END) as total_conversions
            FROM message_logs
            WHERE created_at >= ?
        """, (start_date.isoformat(),))
        
        if result:
            total_sent = result['total_sent'] or 0
            total_replies = result['total_replies'] or 0
            total_conversions = result['total_conversions'] or 0
        else:
            total_sent = total_replies = total_conversions = 0
        
        conversion_rate = (total_conversions / total_sent * 100) if total_sent > 0 else 0
        
        # è¨ˆç®—ä¸ŠæœŸæ•¸æ“šé€²è¡Œå°æ¯”
        if period == 'today':
            prev_start = start_date - timedelta(days=1)
            prev_end = start_date
        elif period == 'week':
            prev_start = start_date - timedelta(days=7)
            prev_end = start_date
        elif period == 'month':
            prev_start = start_date - timedelta(days=30)
            prev_end = start_date
        else:
            prev_start = start_date - timedelta(days=90)
            prev_end = start_date
        
        prev_result = await db.fetch_one("""
            SELECT 
                COUNT(*) as total_sent,
                SUM(CASE WHEN status = 'replied' THEN 1 ELSE 0 END) as total_replies,
                SUM(CASE WHEN status = 'converted' THEN 1 ELSE 0 END) as total_conversions
            FROM message_logs
            WHERE created_at >= ? AND created_at < ?
        """, (prev_start.isoformat(), prev_end.isoformat()))
        
        prev_sent = prev_result['total_sent'] or 0 if prev_result else 0
        prev_replies = prev_result['total_replies'] or 0 if prev_result else 0
        prev_conversions = prev_result['total_conversions'] or 0 if prev_result else 0
        
        # è¨ˆç®—è®ŠåŒ–ç‡
        sent_change = ((total_sent - prev_sent) / prev_sent * 100) if prev_sent > 0 else 0
        replies_change = ((total_replies - prev_replies) / prev_replies * 100) if prev_replies > 0 else 0
        conversions_change = ((total_conversions - prev_conversions) / prev_conversions * 100) if prev_conversions > 0 else 0
        prev_rate = (prev_conversions / prev_sent * 100) if prev_sent > 0 else 0
        rate_change = conversion_rate - prev_rate
        
        self.send_event("analytics:stats", {
            "success": True,
            "stats": {
                "totalSent": total_sent,
                "totalReplies": total_replies,
                "totalConversions": total_conversions,
                "conversionRate": conversion_rate,
                "sentChange": sent_change,
                "repliesChange": replies_change,
                "conversionsChange": conversions_change,
                "rateChange": rate_change
            }
        })
        
    except Exception as e:
        print(f"[Backend] Analytics stats error: {e}", file=sys.stderr)
        self.send_event("analytics:stats", {
            "success": False,
            "error": str(e)
        })

async def handle_analytics_get_trend(self, payload: Dict[str, Any]):
    """ç²å–è¶¨å‹¢æ•¸æ“š"""
    import sys
    from datetime import datetime, timedelta
    
    try:
        period = payload.get('period', 'week')
        print(f"[Backend] Getting analytics trend for period: {period}", file=sys.stderr)
        
        # ç¢ºå®šå¤©æ•¸
        if period == 'today':
            days = 24  # æŒ‰å°æ™‚
        elif period == 'week':
            days = 7
        elif period == 'month':
            days = 30
        else:
            days = 90
        
        trend = []
        now = datetime.now()
        
        for i in range(min(days, 14)):
            date = now - timedelta(days=i)
            date_str = date.strftime('%Y-%m-%d')
            
            result = await db.fetch_one("""
                SELECT 
                    COUNT(*) as sent,
                    SUM(CASE WHEN status = 'replied' THEN 1 ELSE 0 END) as replies,
                    SUM(CASE WHEN status = 'converted' THEN 1 ELSE 0 END) as conversions
                FROM message_logs
                WHERE date(created_at) = ?
            """, (date_str,))
            
            trend.insert(0, {
                "date": date_str,
                "sent": result['sent'] or 0 if result else 0,
                "replies": result['replies'] or 0 if result else 0,
                "conversions": result['conversions'] or 0 if result else 0
            })
        
        self.send_event("analytics:trend", {
            "success": True,
            "trend": trend
        })
        
    except Exception as e:
        print(f"[Backend] Analytics trend error: {e}", file=sys.stderr)
        self.send_event("analytics:trend", {
            "success": False,
            "error": str(e)
        })

async def handle_analytics_get_sources(self, payload: Dict[str, Any]):
    """ç²å–ç”¨æˆ¶ä¾†æºåˆ†å¸ƒ"""
    import sys
    
    try:
        print(f"[Backend] Getting analytics sources", file=sys.stderr)
        
        results = await db.fetch_all("""
            SELECT 
                source_type,
                COUNT(*) as count
            FROM unified_contacts
            GROUP BY source_type
            ORDER BY count DESC
        """)
        
        colors = {
            'extracted_member': '#3b82f6',
            'discovered_resource': '#10b981',
            'captured_lead': '#f59e0b',
            'manual': '#8b5cf6'
        }
        
        source_names = {
            'extracted_member': 'ç¾¤çµ„æå–',
            'discovered_resource': 'é—œéµè©åŒ¹é…',
            'captured_lead': 'æ½›åœ¨å®¢æˆ¶',
            'manual': 'æ‰‹å‹•æ·»åŠ '
        }
        
        sources = []
        total = sum(r['count'] for r in results) if results else 0
        
        for r in results or []:
            source_type = r['source_type']
            count = r['count']
            sources.append({
                "source": source_names.get(source_type, source_type),
                "count": count,
                "percentage": (count / total * 100) if total > 0 else 0,
                "color": colors.get(source_type, '#6b7280')
            })
        
        self.send_event("analytics:sources", {
            "success": True,
            "sources": sources
        })
        
    except Exception as e:
        print(f"[Backend] Analytics sources error: {e}", file=sys.stderr)
        self.send_event("analytics:sources", {
            "success": False,
            "error": str(e)
        })

async def handle_analytics_get_hourly(self, payload: Dict[str, Any]):
    """ç²å–æ™‚æ®µæ•¸æ“š"""
    import sys
    from datetime import datetime, timedelta
    
    try:
        print(f"[Backend] Getting analytics hourly data", file=sys.stderr)
        
        # ç²å–éå»7å¤©çš„æ™‚æ®µæ•¸æ“š
        results = await db.fetch_all("""
            SELECT 
                strftime('%H', created_at) as hour,
                COUNT(*) as sent,
                SUM(CASE WHEN status = 'replied' THEN 1 ELSE 0 END) as replies
            FROM message_logs
            WHERE created_at >= datetime('now', '-7 days')
            GROUP BY hour
        """)
        
        hourly = {}
        for h in range(24):
            hourly[h] = 0
        
        for r in results or []:
            hour = int(r['hour'])
            sent = r['sent'] or 0
            replies = r['replies'] or 0
            # è¨ˆç®—å›è¦†ç‡
            hourly[hour] = int((replies / sent * 100) if sent > 0 else 0)
        
        self.send_event("analytics:hourly", {
            "success": True,
            "hourly": hourly
        })
        
    except Exception as e:
        print(f"[Backend] Analytics hourly error: {e}", file=sys.stderr)
        self.send_event("analytics:hourly", {
            "success": False,
            "error": str(e)
        })

async def handle_analytics_generate_insights(self, payload: Dict[str, Any]):
    """AI ç”Ÿæˆæ´å¯Ÿ"""
    import sys
    
    try:
        stats = payload.get('stats', {})
        period = payload.get('period', 'week')
        print(f"[Backend] Generating AI insights", file=sys.stderr)
        
        # åŸºæ–¼æ•¸æ“šç”Ÿæˆæ´å¯Ÿï¼ˆå¯æ¥å…¥çœŸå¯¦ AIï¼‰
        insights = []
        
        conversion_rate = stats.get('conversionRate', 0)
        if conversion_rate > 5:
            insights.append({
                "icon": "ğŸ‰",
                "type": "success",
                "title": "è½‰åŒ–ç‡è¡¨ç¾å„ªç§€",
                "description": f"ç•¶å‰è½‰åŒ–ç‡ {conversion_rate:.1f}% é«˜æ–¼è¡Œæ¥­å¹³å‡æ°´å¹³ï¼Œç¹¼çºŒä¿æŒï¼"
            })
        elif conversion_rate > 2:
            insights.append({
                "icon": "ğŸ“Š",
                "type": "info",
                "title": "è½‰åŒ–ç‡æ­£å¸¸",
                "description": f"ç•¶å‰è½‰åŒ–ç‡ {conversion_rate:.1f}%ï¼Œè™•æ–¼æ­£å¸¸æ°´å¹³ã€‚"
            })
        else:
            insights.append({
                "icon": "âš ï¸",
                "type": "warning",
                "title": "è½‰åŒ–ç‡æœ‰å¾…æå‡",
                "description": f"ç•¶å‰è½‰åŒ–ç‡ {conversion_rate:.1f}% è¼ƒä½ï¼Œå»ºè­°å„ªåŒ–æ¶ˆæ¯æ¨¡æ¿ã€‚"
            })
        
        sent_change = stats.get('sentChange', 0)
        if sent_change > 10:
            insights.append({
                "icon": "ğŸ“ˆ",
                "type": "info",
                "title": "ç™¼é€é‡é¡¯è‘—å¢é•·",
                "description": f"ç™¼é€é‡è¼ƒä¸ŠæœŸå¢é•· {sent_change:.1f}%ï¼Œè§¸é”æ›´å¤šæ½›åœ¨å®¢æˆ¶ã€‚"
            })
        elif sent_change < -10:
            insights.append({
                "icon": "ğŸ“‰",
                "type": "warning",
                "title": "ç™¼é€é‡ä¸‹é™",
                "description": f"ç™¼é€é‡è¼ƒä¸ŠæœŸä¸‹é™ {abs(sent_change):.1f}%ï¼Œå»ºè­°å¢åŠ ç™¼é€é »ç‡ã€‚"
            })
        
        # æ™‚æ®µå»ºè­°ï¼ˆä½¿ç”¨æ¨¡æ“¬æ•¸æ“šï¼‰
        insights.append({
            "icon": "â°",
            "type": "tip",
            "title": "æœ€ä½³ç™¼é€æ™‚æ®µï¼š10:00-11:00",
            "description": "è©²æ™‚æ®µå›è¦†ç‡æœ€é«˜ï¼Œå»ºè­°é‡é»å®‰æ’ç™¼é€ã€‚"
        })
        
        insights.append({
            "icon": "ğŸ¯",
            "type": "info",
            "title": "æŒçºŒå„ªåŒ–å»ºè­°",
            "description": "å»ºè­°å®šæœŸæ›´æ–°æ¶ˆæ¯æ¨¡æ¿ï¼Œä¿æŒå…§å®¹æ–°é®®åº¦ã€‚"
        })
        
        self.send_event("analytics:insights", {
            "success": True,
            "insights": insights
        })
        
    except Exception as e:
        print(f"[Backend] Analytics insights error: {e}", file=sys.stderr)
        self.send_event("analytics:insights", {
            "success": False,
            "error": str(e)
        })

async def handle_analytics_export(self, payload: Dict[str, Any]):
    """å°å‡ºåˆ†æå ±å‘Š"""
    import sys
    import json
    from datetime import datetime
    
    try:
        print(f"[Backend] Exporting analytics report", file=sys.stderr)
        
        report = {
            "generated_at": datetime.now().isoformat(),
            "period": payload.get('period', 'week'),
            "stats": payload.get('stats', {}),
            "trend": payload.get('trend', []),
            "sources": payload.get('sources', []),
            "insights": payload.get('insights', [])
        }
        
        # é€™è£¡å¯ä»¥ç”Ÿæˆ PDF æˆ– Excel æ–‡ä»¶
        # ç›®å‰åªè¿”å› JSON æ•¸æ“š
        
        self.send_event("analytics:export", {
            "success": True,
            "report": report,
            "format": "json"
        })
        
        self.send_log("ğŸ“Š å ±å‘Šå·²ç”Ÿæˆ", "info")
        
    except Exception as e:
        print(f"[Backend] Analytics export error: {e}", file=sys.stderr)
        self.send_event("analytics:export", {
            "success": False,
            "error": str(e)
        })

