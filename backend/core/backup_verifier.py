"""
ğŸ”§ P10-3: å‚™ä»½é©—è­‰å™¨

åŠŸèƒ½ï¼š
1. é©—è­‰å‚™ä»½æ–‡ä»¶å®Œæ•´æ€§ï¼ˆSQLite quick_checkï¼‰
2. é©—è­‰è¡¨çµæ§‹ä¸€è‡´æ€§
3. é©—è­‰æ•¸æ“šè¡Œæ•¸åˆç†æ€§
4. å¯é¸ï¼šæ¨¡æ“¬æ¢å¾©åˆ°è‡¨æ™‚ç›®éŒ„
5. å®šæœŸè‡ªå‹•é©—è­‰ï¼ˆé›†æˆåˆ° daily maintenanceï¼‰
"""

import os
import sys
import time
import sqlite3
import tempfile
import shutil
import logging
import zipfile
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


@dataclass
class VerificationResult:
    """å‚™ä»½é©—è­‰çµæœ"""
    backup_path: str
    is_valid: bool = True
    file_size: int = 0
    checks_passed: int = 0
    checks_failed: int = 0
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    details: Dict[str, Any] = field(default_factory=dict)
    duration_ms: float = 0

    def to_dict(self) -> Dict[str, Any]:
        return {
            'backup_path': self.backup_path,
            'is_valid': self.is_valid,
            'file_size': self.file_size,
            'checks_passed': self.checks_passed,
            'checks_failed': self.checks_failed,
            'errors': self.errors,
            'warnings': self.warnings,
            'details': self.details,
            'duration_ms': self.duration_ms,
        }


class BackupVerifier:
    """å‚™ä»½é©—è­‰å™¨"""

    # æ ¸å¿ƒè¡¨åˆ—è¡¨ â€” é€™äº›è¡¨åœ¨ä»»ä½•æœ‰æ•ˆå‚™ä»½ä¸­éƒ½æ‡‰å­˜åœ¨
    CORE_TABLES = [
        'users',
        'accounts',
    ]

    # å·²çŸ¥çš„å¯é¸è¡¨ï¼ˆä¸å¼·åˆ¶è¦æ±‚å­˜åœ¨ï¼‰
    OPTIONAL_TABLES = [
        'keyword_sets', 'keywords', 'monitored_groups',
        'templates', 'campaigns', 'captured_leads',
        'schema_version', 'frontend_audit_log',
        'performance_metrics',
    ]

    def __init__(self):
        pass

    def verify_backup(self, backup_path: str, full_restore_test: bool = False) -> VerificationResult:
        """
        é©—è­‰å‚™ä»½æ–‡ä»¶

        Args:
            backup_path: å‚™ä»½æ–‡ä»¶è·¯å¾‘ï¼ˆ.db æˆ– .zipï¼‰
            full_restore_test: æ˜¯å¦åŸ·è¡Œå®Œæ•´æ¢å¾©æ¸¬è©¦

        Returns:
            VerificationResult
        """
        start_time = time.time()
        result = VerificationResult(backup_path=backup_path)

        try:
            # 1. æ–‡ä»¶å­˜åœ¨æ€§å’Œå¤§å°
            if not os.path.exists(backup_path):
                result.errors.append(f"Backup file not found: {backup_path}")
                result.is_valid = False
                return result

            result.file_size = os.path.getsize(backup_path)
            if result.file_size == 0:
                result.errors.append("Backup file is empty (0 bytes)")
                result.is_valid = False
                return result

            result.checks_passed += 1

            # 2. è™•ç† ZIP æ ¼å¼
            db_path = backup_path
            temp_dir = None

            if backup_path.endswith('.zip'):
                temp_dir = tempfile.mkdtemp(prefix='backup_verify_')
                try:
                    with zipfile.ZipFile(backup_path, 'r') as zf:
                        # æŸ¥æ‰¾ .db æ–‡ä»¶
                        db_files = [f for f in zf.namelist() if f.endswith('.db')]
                        if not db_files:
                            result.errors.append("ZIP backup contains no .db file")
                            result.is_valid = False
                            return result
                        zf.extract(db_files[0], temp_dir)
                        db_path = os.path.join(temp_dir, db_files[0])
                    result.checks_passed += 1
                except zipfile.BadZipFile:
                    result.errors.append("Corrupt ZIP file")
                    result.is_valid = False
                    return result

            # 3. SQLite å®Œæ•´æ€§æª¢æŸ¥
            try:
                conn = sqlite3.connect(db_path, timeout=10)
                conn.row_factory = sqlite3.Row

                # quick_check
                integrity = conn.execute('PRAGMA quick_check').fetchone()
                if integrity and integrity[0] == 'ok':
                    result.checks_passed += 1
                    result.details['integrity'] = 'ok'
                else:
                    result.errors.append(f"Integrity check failed: {integrity}")
                    result.is_valid = False

                # 4. è¡¨çµæ§‹æª¢æŸ¥
                tables = [row[0] for row in conn.execute(
                    "SELECT name FROM sqlite_master WHERE type='table' ORDER BY name"
                ).fetchall()]
                result.details['tables'] = tables
                result.details['table_count'] = len(tables)

                for core_table in self.CORE_TABLES:
                    if core_table in tables:
                        result.checks_passed += 1
                    else:
                        result.warnings.append(f"Core table missing: {core_table}")

                # 5. æ•¸æ“šè¡Œæ•¸æª¢æŸ¥
                row_counts = {}
                for table in tables:
                    try:
                        count = conn.execute(f'SELECT COUNT(*) FROM [{table}]').fetchone()[0]
                        row_counts[table] = count
                    except Exception:
                        row_counts[table] = -1

                result.details['row_counts'] = row_counts
                total_rows = sum(c for c in row_counts.values() if c > 0)
                result.details['total_rows'] = total_rows

                if total_rows > 0:
                    result.checks_passed += 1
                else:
                    result.warnings.append("Backup contains 0 data rows")

                # 6. schema_version æª¢æŸ¥
                if 'schema_version' in tables:
                    versions = conn.execute(
                        'SELECT version, applied_at FROM schema_version ORDER BY version DESC LIMIT 1'
                    ).fetchone()
                    if versions:
                        result.details['latest_schema_version'] = versions[0]
                        result.details['latest_migration_date'] = versions[1]
                        result.checks_passed += 1

                conn.close()

            except sqlite3.DatabaseError as db_err:
                result.errors.append(f"SQLite error: {db_err}")
                result.is_valid = False

            # 7. å®Œæ•´æ¢å¾©æ¸¬è©¦ï¼ˆå¯é¸ï¼‰
            if full_restore_test and result.is_valid:
                restore_result = self._test_full_restore(db_path)
                if restore_result:
                    result.checks_passed += 1
                    result.details['restore_test'] = 'passed'
                else:
                    result.warnings.append("Full restore test failed")
                    result.details['restore_test'] = 'failed'

            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            if temp_dir and os.path.exists(temp_dir):
                shutil.rmtree(temp_dir, ignore_errors=True)

        except Exception as e:
            result.errors.append(f"Unexpected error: {e}")
            result.is_valid = False

        result.duration_ms = (time.time() - start_time) * 1000
        result.checks_failed = len(result.errors)
        return result

    def _test_full_restore(self, db_path: str) -> bool:
        """æ¨¡æ“¬å®Œæ•´æ¢å¾©ï¼šè¤‡è£½åˆ°è‡¨æ™‚ä½ç½®ä¸¦é©—è­‰å¯è®€"""
        temp_db = None
        try:
            fd, temp_db = tempfile.mkstemp(suffix='.db')
            os.close(fd)
            shutil.copy2(db_path, temp_db)

            conn = sqlite3.connect(temp_db, timeout=5)
            # å˜—è©¦ä¸€å€‹åŸºæœ¬è®€å–æ“ä½œ
            conn.execute('SELECT 1')
            tables = conn.execute(
                "SELECT COUNT(*) FROM sqlite_master WHERE type='table'"
            ).fetchone()[0]
            conn.close()

            return tables > 0

        except Exception as e:
            logger.warning(f"Full restore test failed: {e}")
            return False
        finally:
            if temp_db and os.path.exists(temp_db):
                os.unlink(temp_db)

    def verify_latest_backup(self, backup_dir: str) -> Optional[VerificationResult]:
        """é©—è­‰æœ€æ–°çš„å‚™ä»½æ–‡ä»¶"""
        backup_path = Path(backup_dir)
        if not backup_path.exists():
            return None

        # æ‰¾åˆ°æœ€æ–°çš„å‚™ä»½æ–‡ä»¶
        backup_files = sorted(
            [f for f in backup_path.glob('**/*.db')] +
            [f for f in backup_path.glob('**/*.zip')],
            key=lambda f: f.stat().st_mtime,
            reverse=True
        )

        if not backup_files:
            return None

        return self.verify_backup(str(backup_files[0]))


def verify_backup_on_schedule(backup_dir: str) -> Dict[str, Any]:
    """
    å®šæ™‚å‚™ä»½é©—è­‰ï¼ˆé›†æˆåˆ° daily maintenanceï¼‰

    Returns:
        é©—è­‰çµæœå­—å…¸
    """
    verifier = BackupVerifier()
    result = verifier.verify_latest_backup(backup_dir)

    if result is None:
        return {'status': 'no_backups', 'message': 'No backup files found'}

    summary = result.to_dict()
    if result.is_valid:
        print(f"[BackupVerify] âœ… Latest backup valid: {result.backup_path} "
              f"({result.file_size} bytes, {result.checks_passed} checks passed, "
              f"{result.duration_ms:.0f}ms)", file=sys.stderr)
    else:
        print(f"[BackupVerify] âŒ Backup INVALID: {result.backup_path} "
              f"Errors: {result.errors}", file=sys.stderr)

    return summary
