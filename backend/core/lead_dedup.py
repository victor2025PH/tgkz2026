"""
ðŸ”§ P12-2: ç·šç´¢åŽ»é‡æœå‹™

åŠŸèƒ½ï¼š
1. åŸºæ–¼ telegram_id çš„ç²¾ç¢ºåŽ»é‡
2. åŸºæ–¼ username + first_name çš„æ¨¡ç³ŠåŽ»é‡
3. åˆä½µç­–ç•¥ï¼šä¿ç•™æœ€æ–°æ•¸æ“š + ç´¯åŠ äº’å‹•è¨ˆæ•¸
4. æ‰¹é‡åŽ»é‡æŽƒæ
"""

import logging
import sqlite3
from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class DuplicateGroup:
    """é‡è¤‡ç·šç´¢çµ„"""
    primary_id: int
    duplicate_ids: List[int]
    match_type: str  # exact_telegram_id, fuzzy_username
    confidence: float  # 0-1
    details: Dict[str, Any]

    def to_dict(self) -> Dict[str, Any]:
        return {
            'primary_id': self.primary_id,
            'duplicate_ids': self.duplicate_ids,
            'match_type': self.match_type,
            'confidence': self.confidence,
            'details': self.details,
        }


class LeadDeduplicationService:
    """ç·šç´¢åŽ»é‡æœå‹™"""

    def __init__(self, db_path: str = None):
        self.db_path = db_path

    def _get_conn(self) -> sqlite3.Connection:
        if self.db_path:
            conn = sqlite3.connect(self.db_path)
        else:
            from core.db_utils import get_connection
            conn = get_connection().__enter__()
        conn.row_factory = sqlite3.Row
        return conn

    def scan_duplicates(self, limit: int = 100) -> List[DuplicateGroup]:
        """
        æŽƒæé‡è¤‡ç·šç´¢

        Returns:
            é‡è¤‡çµ„åˆ—è¡¨
        """
        groups = []

        try:
            conn = self._get_conn()

            # 1. ç²¾ç¢ºé‡è¤‡ï¼šç›¸åŒ telegram_id å‡ºç¾å¤šæ¬¡ï¼ˆç†è«–ä¸Šä¸æ‡‰è©²ï¼Œå› ç‚º UNIQUEï¼‰
            # ä½†èˆŠæ•¸æ“šå¯èƒ½åœ¨ extracted_members å’Œ unified_contacts éƒ½æœ‰

            # 2. æ¨¡ç³Šé‡è¤‡ï¼šç›¸åŒ usernameï¼ˆå¿½ç•¥å¤§å°å¯«ï¼‰
            rows = conn.execute('''
                SELECT LOWER(username) as norm_username, GROUP_CONCAT(id) as ids, COUNT(*) as cnt
                FROM unified_contacts
                WHERE username IS NOT NULL AND username != ''
                GROUP BY LOWER(username)
                HAVING COUNT(*) > 1
                ORDER BY cnt DESC
                LIMIT ?
            ''', (limit,)).fetchall()

            for row in rows:
                ids = [int(i) for i in row['ids'].split(',')]
                groups.append(DuplicateGroup(
                    primary_id=ids[0],
                    duplicate_ids=ids[1:],
                    match_type='fuzzy_username',
                    confidence=0.9,
                    details={
                        'username': row['norm_username'],
                        'count': row['cnt'],
                    }
                ))

            # 3. æ¨¡ç³Šé‡è¤‡ï¼šç›¸åŒ phone
            rows = conn.execute('''
                SELECT phone, GROUP_CONCAT(id) as ids, COUNT(*) as cnt
                FROM unified_contacts
                WHERE phone IS NOT NULL AND phone != ''
                GROUP BY phone
                HAVING COUNT(*) > 1
                ORDER BY cnt DESC
                LIMIT ?
            ''', (limit,)).fetchall()

            for row in rows:
                ids = [int(i) for i in row['ids'].split(',')]
                groups.append(DuplicateGroup(
                    primary_id=ids[0],
                    duplicate_ids=ids[1:],
                    match_type='exact_phone',
                    confidence=0.95,
                    details={
                        'phone': row['phone'],
                        'count': row['cnt'],
                    }
                ))

            conn.close()

        except Exception as e:
            logger.error(f"Duplicate scan error: {e}")

        return groups

    def merge_duplicates(self, primary_id: int, duplicate_ids: List[int]) -> Dict[str, Any]:
        """
        åˆä½µé‡è¤‡ç·šç´¢

        ç­–ç•¥ï¼š
        - ä¿ç•™ primary_id è¨˜éŒ„
        - å¾ž duplicates ä¸­åˆä½µæ•¸æ“šï¼ˆå–æœ€æ–°éžç©ºå€¼ï¼‰
        - ç´¯åŠ äº’å‹•è¨ˆæ•¸
        - åˆä½µæ¨™ç±¤
        - åˆªé™¤é‡è¤‡è¨˜éŒ„
        """
        if not duplicate_ids:
            return {'merged': 0, 'kept': primary_id}

        try:
            conn = self._get_conn()

            # ç²å–æ‰€æœ‰ç›¸é—œè¨˜éŒ„
            all_ids = [primary_id] + duplicate_ids
            placeholders = ','.join('?' * len(all_ids))
            rows = conn.execute(
                f'SELECT * FROM unified_contacts WHERE id IN ({placeholders})',
                all_ids
            ).fetchall()

            if not rows:
                return {'error': 'Records not found'}

            # æ§‹å»ºåˆä½µæ•¸æ“š
            merged_data = {}
            total_messages = 0
            total_interactions = 0
            all_tags = set()

            for row in rows:
                row_dict = dict(row)
                # å–æœ€æ–°çš„éžç©ºå€¼
                for field in ('display_name', 'first_name', 'last_name', 'bio', 'phone'):
                    if row_dict.get(field) and not merged_data.get(field):
                        merged_data[field] = row_dict[field]

                # ç´¯åŠ è¨ˆæ•¸ï¼ˆå®‰å…¨è™•ç†å¯èƒ½ä¸å­˜åœ¨çš„åˆ—ï¼‰
                total_messages += (row_dict.get('message_count') or 0)
                if 'interactions_count' in row_dict:
                    total_interactions += (row_dict.get('interactions_count') or 0)

                # åˆä½µæ¨™ç±¤
                tags_str = row_dict.get('tags') or ''
                if tags_str:
                    for tag in tags_str.split(','):
                        tag = tag.strip()
                        if tag:
                            all_tags.add(tag)

            # æ›´æ–° primary è¨˜éŒ„
            update_fields = []
            update_values = []
            for field, value in merged_data.items():
                update_fields.append(f"{field} = COALESCE(?, {field})")
                update_values.append(value)

            update_fields.append("message_count = ?")
            update_values.append(total_messages)

            # interactions_count åˆ—å¯èƒ½ä¸å­˜åœ¨ï¼ˆèˆŠç‰ˆæœ¬ schemaï¼‰
            try:
                conn.execute('SELECT interactions_count FROM unified_contacts LIMIT 0')
                update_fields.append("interactions_count = ?")
                update_values.append(total_interactions)
            except sqlite3.OperationalError:
                pass  # åˆ—ä¸å­˜åœ¨ï¼Œè·³éŽ

            if all_tags:
                update_fields.append("tags = ?")
                update_values.append(','.join(sorted(all_tags)))

            update_fields.append("updated_at = CURRENT_TIMESTAMP")
            update_values.append(primary_id)

            conn.execute(
                f"UPDATE unified_contacts SET {', '.join(update_fields)} WHERE id = ?",
                update_values
            )

            # åˆªé™¤é‡è¤‡è¨˜éŒ„
            dup_placeholders = ','.join('?' * len(duplicate_ids))
            conn.execute(
                f"DELETE FROM unified_contacts WHERE id IN ({dup_placeholders})",
                duplicate_ids
            )

            conn.commit()
            conn.close()

            return {
                'merged': len(duplicate_ids),
                'kept': primary_id,
                'total_messages': total_messages,
                'tags': list(all_tags),
            }

        except Exception as e:
            logger.error(f"Merge error: {e}")
            return {'error': str(e)}

    def get_dedup_stats(self) -> Dict[str, Any]:
        """ç²å–åŽ»é‡çµ±è¨ˆ"""
        try:
            conn = self._get_conn()
            total = conn.execute('SELECT COUNT(*) FROM unified_contacts').fetchone()[0]
            with_username = conn.execute(
                "SELECT COUNT(*) FROM unified_contacts WHERE username IS NOT NULL AND username != ''"
            ).fetchone()[0]

            # é‡è¤‡ username è¨ˆæ•¸
            dup_username = conn.execute('''
                SELECT COUNT(*) FROM (
                    SELECT LOWER(username) FROM unified_contacts
                    WHERE username IS NOT NULL AND username != ''
                    GROUP BY LOWER(username) HAVING COUNT(*) > 1
                )
            ''').fetchone()[0]

            conn.close()

            return {
                'total_contacts': total,
                'with_username': with_username,
                'duplicate_username_groups': dup_username,
                'estimated_duplicates': dup_username * 2,  # ç²—ç•¥ä¼°è¨ˆ
            }
        except Exception as e:
            return {'error': str(e)}
