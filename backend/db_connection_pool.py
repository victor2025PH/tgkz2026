"""
ğŸ”§ Phase 3 å„ªåŒ–ï¼šSQLite é€£æ¥æ± å’ŒæŸ¥è©¢å„ªåŒ–

åŠŸèƒ½ï¼š
1. é€£æ¥æ± ç®¡ç†ï¼ˆæ¸›å°‘é€£æ¥é–‹éŠ·ï¼‰
2. æŸ¥è©¢ç·©å­˜
3. æ…¢æŸ¥è©¢æ—¥èªŒ
4. è‡ªå‹•é‡é€£
"""

import sys
import asyncio
import sqlite3
import time
from typing import Dict, Any, Optional, List, Callable
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from collections import OrderedDict
from datetime import datetime

try:
    import aiosqlite
    HAS_AIOSQLITE = True
except ImportError:
    HAS_AIOSQLITE = False
    aiosqlite = None


@dataclass
class QueryStats:
    """æŸ¥è©¢çµ±è¨ˆ"""
    query: str
    count: int = 0
    total_time: float = 0.0
    max_time: float = 0.0
    last_executed: Optional[datetime] = None
    
    @property
    def avg_time(self) -> float:
        return self.total_time / self.count if self.count > 0 else 0.0


class ConnectionPool:
    """
    SQLite é€£æ¥æ± 
    
    ç”±æ–¼ SQLite æ˜¯æ–‡ä»¶é–ï¼Œä¸æ”¯æŒçœŸæ­£çš„é€£æ¥æ± ï¼Œ
    ä½†æˆ‘å€‘å¯ä»¥å„ªåŒ–é€£æ¥å¾©ç”¨å’Œç®¡ç†ã€‚
    """
    
    def __init__(
        self,
        db_path: str,
        max_connections: int = 5,
        timeout: float = 30.0,
        slow_query_threshold: float = 0.5,  # 0.5ç§’ä»¥ä¸Šç‚ºæ…¢æŸ¥è©¢
    ):
        self.db_path = db_path
        self.max_connections = max_connections
        self.timeout = timeout
        self.slow_query_threshold = slow_query_threshold
        
        # é€£æ¥æ± 
        self._connections: List[Any] = []
        self._in_use: set = set()
        self._lock = asyncio.Lock()
        
        # æŸ¥è©¢çµ±è¨ˆ
        self._query_stats: Dict[str, QueryStats] = {}
        self._slow_queries: List[Dict[str, Any]] = []
        self._max_slow_queries = 100
        
        # ç·©å­˜
        self._query_cache: OrderedDict = OrderedDict()
        self._cache_max_size = 200
        self._cache_ttl = 60.0  # 60ç§’
        self._cache_timestamps: Dict[str, float] = {}
        
        # çµ±è¨ˆ
        self._stats = {
            'connections_created': 0,
            'connections_reused': 0,
            'queries_executed': 0,
            'cache_hits': 0,
            'cache_misses': 0,
        }
    
    async def _create_connection(self) -> Any:
        """å‰µå»ºæ–°é€£æ¥"""
        if not HAS_AIOSQLITE:
            raise ImportError("aiosqlite is required")
        
        conn = await aiosqlite.connect(self.db_path, timeout=self.timeout)
        conn.row_factory = aiosqlite.Row
        
        # å„ªåŒ–è¨­ç½®
        await conn.execute("PRAGMA journal_mode=WAL")
        await conn.execute("PRAGMA synchronous=NORMAL")
        await conn.execute("PRAGMA cache_size=-64000")  # 64MB
        await conn.execute("PRAGMA busy_timeout=30000")
        await conn.execute("PRAGMA temp_store=MEMORY")  # è‡¨æ™‚è¡¨å­˜å…§å­˜
        await conn.execute("PRAGMA mmap_size=268435456")  # 256MB å…§å­˜æ˜ å°„
        
        self._stats['connections_created'] += 1
        return conn
    
    @asynccontextmanager
    async def acquire(self):
        """ç²å–é€£æ¥"""
        async with self._lock:
            # å˜—è©¦å¾©ç”¨ç¾æœ‰é€£æ¥
            for conn in self._connections:
                if id(conn) not in self._in_use:
                    self._in_use.add(id(conn))
                    self._stats['connections_reused'] += 1
                    try:
                        yield conn
                    finally:
                        self._in_use.discard(id(conn))
                    return
            
            # å‰µå»ºæ–°é€£æ¥ï¼ˆå¦‚æœæœªé”ä¸Šé™ï¼‰
            if len(self._connections) < self.max_connections:
                conn = await self._create_connection()
                self._connections.append(conn)
                self._in_use.add(id(conn))
                try:
                    yield conn
                finally:
                    self._in_use.discard(id(conn))
                return
        
        # ç­‰å¾…å¯ç”¨é€£æ¥
        while True:
            await asyncio.sleep(0.1)
            async with self._lock:
                for conn in self._connections:
                    if id(conn) not in self._in_use:
                        self._in_use.add(id(conn))
                        self._stats['connections_reused'] += 1
                        try:
                            yield conn
                        finally:
                            self._in_use.discard(id(conn))
                        return
    
    async def execute(
        self,
        query: str,
        params: tuple = (),
        use_cache: bool = False,
        cache_key: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """åŸ·è¡ŒæŸ¥è©¢"""
        # æª¢æŸ¥ç·©å­˜
        if use_cache:
            key = cache_key or f"{query}:{params}"
            cached = self._get_cached(key)
            if cached is not None:
                self._stats['cache_hits'] += 1
                return cached
            self._stats['cache_misses'] += 1
        
        # åŸ·è¡ŒæŸ¥è©¢
        start_time = time.time()
        
        async with self.acquire() as conn:
            cursor = await conn.execute(query, params)
            rows = await cursor.fetchall()
            result = [dict(row) for row in rows]
        
        elapsed = time.time() - start_time
        self._stats['queries_executed'] += 1
        
        # è¨˜éŒ„çµ±è¨ˆ
        self._record_query_stats(query, elapsed)
        
        # æª¢æŸ¥æ…¢æŸ¥è©¢
        if elapsed > self.slow_query_threshold:
            self._record_slow_query(query, params, elapsed)
        
        # ç·©å­˜çµæœ
        if use_cache:
            self._set_cached(key, result)
        
        return result
    
    async def execute_write(self, query: str, params: tuple = ()) -> int:
        """åŸ·è¡Œå¯«å…¥æ“ä½œ"""
        start_time = time.time()
        
        async with self.acquire() as conn:
            cursor = await conn.execute(query, params)
            await conn.commit()
            rowcount = cursor.rowcount
        
        elapsed = time.time() - start_time
        self._stats['queries_executed'] += 1
        self._record_query_stats(query, elapsed)
        
        if elapsed > self.slow_query_threshold:
            self._record_slow_query(query, params, elapsed)
        
        # æ¸…é™¤ç›¸é—œç·©å­˜
        self._invalidate_cache_by_table(query)
        
        return rowcount
    
    def _get_cached(self, key: str) -> Optional[List[Dict]]:
        """ç²å–ç·©å­˜"""
        if key in self._query_cache:
            timestamp = self._cache_timestamps.get(key, 0)
            if time.time() - timestamp < self._cache_ttl:
                # ç§»åˆ°æœ€å¾Œï¼ˆLRUï¼‰
                self._query_cache.move_to_end(key)
                return self._query_cache[key]
            else:
                # éæœŸ
                del self._query_cache[key]
                del self._cache_timestamps[key]
        return None
    
    def _set_cached(self, key: str, value: List[Dict]):
        """è¨­ç½®ç·©å­˜"""
        # LRU æ·˜æ±°
        while len(self._query_cache) >= self._cache_max_size:
            oldest_key = next(iter(self._query_cache))
            del self._query_cache[oldest_key]
            self._cache_timestamps.pop(oldest_key, None)
        
        self._query_cache[key] = value
        self._cache_timestamps[key] = time.time()
    
    def _invalidate_cache_by_table(self, query: str):
        """æ ¹æ“šè¡¨åæ¸…é™¤ç›¸é—œç·©å­˜"""
        # æå–è¡¨å
        query_upper = query.upper()
        for keyword in ['INSERT INTO', 'UPDATE', 'DELETE FROM']:
            if keyword in query_upper:
                # æ¸…é™¤æ‰€æœ‰ç·©å­˜ï¼ˆç°¡å–®å¯¦ç¾ï¼‰
                self._query_cache.clear()
                self._cache_timestamps.clear()
                break
    
    def _record_query_stats(self, query: str, elapsed: float):
        """è¨˜éŒ„æŸ¥è©¢çµ±è¨ˆ"""
        # æ¨™æº–åŒ–æŸ¥è©¢ï¼ˆç§»é™¤åƒæ•¸ï¼‰
        normalized = self._normalize_query(query)
        
        if normalized not in self._query_stats:
            self._query_stats[normalized] = QueryStats(query=normalized)
        
        stats = self._query_stats[normalized]
        stats.count += 1
        stats.total_time += elapsed
        stats.max_time = max(stats.max_time, elapsed)
        stats.last_executed = datetime.now()
    
    def _normalize_query(self, query: str) -> str:
        """æ¨™æº–åŒ–æŸ¥è©¢ï¼ˆç”¨æ–¼çµ±è¨ˆï¼‰"""
        # ç°¡å–®å¯¦ç¾ï¼šå–å‰100å€‹å­—ç¬¦
        return query[:100].strip()
    
    def _record_slow_query(self, query: str, params: tuple, elapsed: float):
        """è¨˜éŒ„æ…¢æŸ¥è©¢"""
        self._slow_queries.append({
            'query': query[:200],
            'params': str(params)[:100],
            'elapsed': round(elapsed, 3),
            'timestamp': datetime.now().isoformat(),
        })
        
        # é™åˆ¶æ•¸é‡
        if len(self._slow_queries) > self._max_slow_queries:
            self._slow_queries = self._slow_queries[-self._max_slow_queries:]
        
        print(f"[DB] âš ï¸ æ…¢æŸ¥è©¢ ({elapsed:.2f}s): {query[:80]}...", file=sys.stderr)
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        return {
            **self._stats,
            'pool_size': len(self._connections),
            'in_use': len(self._in_use),
            'cache_size': len(self._query_cache),
            'slow_queries': len(self._slow_queries),
        }
    
    def get_slow_queries(self, limit: int = 20) -> List[Dict]:
        """ç²å–æ…¢æŸ¥è©¢åˆ—è¡¨"""
        return self._slow_queries[-limit:]
    
    def get_top_queries(self, limit: int = 10) -> List[Dict]:
        """ç²å–æœ€å¸¸åŸ·è¡Œçš„æŸ¥è©¢"""
        sorted_stats = sorted(
            self._query_stats.values(),
            key=lambda x: x.count,
            reverse=True
        )[:limit]
        
        return [
            {
                'query': s.query,
                'count': s.count,
                'avg_time': round(s.avg_time, 4),
                'max_time': round(s.max_time, 4),
            }
            for s in sorted_stats
        ]
    
    async def close_all(self):
        """é—œé–‰æ‰€æœ‰é€£æ¥"""
        async with self._lock:
            for conn in self._connections:
                try:
                    await conn.close()
                except Exception:
                    pass
            self._connections.clear()
            self._in_use.clear()
        print(f"[DB] å·²é—œé–‰ {self._stats['connections_created']} å€‹é€£æ¥", file=sys.stderr)


# å…¨å±€é€£æ¥æ± 
_connection_pool: Optional[ConnectionPool] = None


def get_connection_pool() -> Optional[ConnectionPool]:
    """ç²å–é€£æ¥æ± """
    return _connection_pool


async def init_connection_pool(db_path: str) -> ConnectionPool:
    """åˆå§‹åŒ–é€£æ¥æ± """
    global _connection_pool
    if _connection_pool is None:
        _connection_pool = ConnectionPool(db_path)
        print(f"[DB] âœ“ é€£æ¥æ± å·²åˆå§‹åŒ–", file=sys.stderr)
    return _connection_pool
