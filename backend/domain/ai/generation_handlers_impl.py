"""
Extracted handler implementations: ai_generation
Auto-generated by refactor_main.py
"""
import json
import sys
import time
import asyncio
import traceback
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from service_context import get_service_context
from database import db

# All handlers receive (self, payload) where self is BackendService instance.
# They are called via: await handler_impl(self, payload)
# Inside, use self.db, self.send_event(), self.telegram_manager, etc.
# This is a transitional pattern - later, replace self.xxx with ctx.xxx


# ==================== AI Generation Handlers ====================

async def handle_ai_generate_message(self, payload: Dict[str, Any]):
    """AI ç”Ÿæˆæ‰¹é‡ç™¼é€æ¶ˆæ¯ - å„ªå…ˆä½¿ç”¨é…ç½®çš„ AIï¼Œå›é€€åˆ°æœ¬åœ°æ¨¡æ¿"""
    import sys
    import random
    import aiohttp
    
    try:
        topic = payload.get('topic', 'æ‰“æ‹›å‘¼')
        style = payload.get('style', 'friendly')
        count = payload.get('count', 5)
        context = payload.get('context', {})
        owner_user_id = payload.get('ownerUserId')
        
        # é…é¡æª¢æŸ¥ï¼ˆæ ¹æ“šç”Ÿæˆæ•¸é‡è¨ˆç®—æ¶ˆè€—ï¼‰
        ai_cost = max(1, count // 3)  # æ¯ 3 æ¢æ¶ˆæ¯æ¶ˆè€— 1 æ¬¡ AI é…é¡
        quota_check = await self.check_quota('ai_calls', ai_cost, owner_user_id)
        if not quota_check.get('allowed', True):
            self.send_quota_exceeded_error('ai-generate-message-result', 'ai_calls', quota_check.get('result', {}))
            return
        
        print(f"[AI] ç”Ÿæˆæ¶ˆæ¯: topic={topic}, style={style}, count={count}", file=sys.stderr)
        
        # å˜—è©¦ç²å–é…ç½®çš„ AI æ¨¡å‹
        ai_model = await self._get_default_ai_model()
        
        if ai_model:
            print(f"[AI] ä½¿ç”¨é…ç½®çš„ AI: {ai_model.get('displayName')} ({ai_model.get('provider')})", file=sys.stderr)
            self.send_log(f"ğŸ¤– ä½¿ç”¨ {ai_model.get('displayName')} ç”Ÿæˆæ¶ˆæ¯...", "info")
            
            # å˜—è©¦èª¿ç”¨çœŸæ­£çš„ AI
            try:
                messages = await self._generate_messages_with_ai(
                    ai_model, topic, style, count
                )
                if messages:
                    self.send_event("ai-generate-message-result", {
                        "success": True,
                        "messages": messages,
                        "source": "ai",
                        "model": ai_model.get('displayName')
                    })
                    return
            except Exception as ai_error:
                print(f"[AI] AI èª¿ç”¨å¤±æ•—ï¼Œå›é€€åˆ°æœ¬åœ°æ¨¡æ¿: {ai_error}", file=sys.stderr)
                self.send_log(f"âš ï¸ AI èª¿ç”¨å¤±æ•—ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ¿: {ai_error}", "warning")
        else:
            print(f"[AI] æœªé…ç½® AI æ¨¡å‹ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ¿", file=sys.stderr)
        
        # å›é€€ï¼šä½¿ç”¨æœ¬åœ°æ¨¡æ¿
        messages = self._get_local_message_templates(topic, style, count)
        
        self.send_event("ai-generate-message-result", {
            "success": True,
            "messages": messages,
            "source": "local",
            "model": None
        })
        
    except Exception as e:
        print(f"[AI] ç”Ÿæˆæ¶ˆæ¯å¤±æ•—: {e}", file=sys.stderr)
        self.send_event("ai-generate-message-result", {
            "success": False,
            "error": str(e)
        })


async def handle_ai_generate_text(self, payload: Dict[str, Any]):
    """
    ğŸ†• P0: é€šç”¨ AI æ–‡æœ¬ç”Ÿæˆ handler
    æ”¯æŒå¤šè§’è‰²å”ä½œç­‰æ¨¡å¡Šèª¿ç”¨ AI ç”Ÿæˆæ–‡æœ¬
    ğŸ”§ P1: æ·»åŠ é‡è©¦æ©Ÿåˆ¶
    ğŸ”§ P4.3: æ·»åŠ é…é¡æª¢æŸ¥
    """
    import sys
    import aiohttp
    
    # ğŸ”§ èª¿è©¦ï¼šç«‹å³æ‰“å°ç¢ºèªæ”¶åˆ°å‘½ä»¤
    print(f"[AI] ========== handle_ai_generate_text è¢«èª¿ç”¨ ==========", file=sys.stderr)
    print(f"[AI] payload keys: {list(payload.keys()) if payload else 'None'}", file=sys.stderr)
    
    try:
        prompt = payload.get('prompt', '')
        max_tokens = payload.get('maxTokens', 500)
        callback = payload.get('callback', 'ai:generate-text-result')
        response_format = payload.get('responseFormat', 'text')  # text æˆ– json
        owner_user_id = payload.get('ownerUserId')
        
        # é…é¡æª¢æŸ¥
        quota_check = await self.check_quota('ai_calls', 1, owner_user_id)
        if not quota_check.get('allowed', True):
            self.send_event(callback, {
                "success": False,
                "error": "AI èª¿ç”¨é…é¡å·²ç”¨ç›¡",
                "code": "QUOTA_EXCEEDED",
                "quota": quota_check.get('result', {})
            })
            return
        
        print(f"[AI] callback={callback}, prompté•·åº¦={len(prompt)}", file=sys.stderr)
        
        if not prompt:
            print(f"[AI] éŒ¯èª¤ï¼šç¼ºå°‘ prompt åƒæ•¸", file=sys.stderr)
            self.send_event(callback, {"success": False, "error": "ç¼ºå°‘ prompt åƒæ•¸"})
            return
        
        print(f"[AI] é€šç”¨æ–‡æœ¬ç”Ÿæˆ: prompté•·åº¦={len(prompt)}, callback={callback}", file=sys.stderr)
        
        # ç²å– AI æ¨¡å‹
        ai_model = await self._get_default_ai_model()
        
        if not ai_model:
            print(f"[AI] æœªé…ç½® AI æ¨¡å‹ï¼Œç„¡æ³•ç”Ÿæˆ", file=sys.stderr)
            self.send_event(callback, {
                "success": False,
                "error": "æœªé…ç½® AI æ¨¡å‹",
                "text": None
            })
            return
        
        print(f"[AI] ä½¿ç”¨æ¨¡å‹: {ai_model.get('displayName')} ({ai_model.get('provider')})", file=sys.stderr)
        
        # ğŸ”§ P1: æ·»åŠ é‡è©¦æ©Ÿåˆ¶ï¼ˆä½¿ç”¨é…ç½®å¸¸é‡ï¼‰
        from config import AIConfig
        result_text = None
        last_error = None
        
        for attempt in range(AIConfig.MAX_RETRIES + 1):
            if attempt > 0:
                print(f"[AI] é‡è©¦ç¬¬ {attempt} æ¬¡...", file=sys.stderr)
                await asyncio.sleep(AIConfig.RETRY_DELAY_SECONDS)
            
            result_text = await self._call_ai_for_text(ai_model, prompt, max_tokens)
            
            if result_text:
                break
            else:
                last_error = "AI ç”Ÿæˆå¤±æ•—"
        
        if result_text:
            print(f"[AI] ç”ŸæˆæˆåŠŸï¼Œé•·åº¦: {len(result_text)}", file=sys.stderr)
            self.send_event(callback, {
                "success": True,
                "text": result_text,
                "model": ai_model.get('displayName'),
                "provider": ai_model.get('provider')
            })
        else:
            print(f"[AI] æ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—", file=sys.stderr)
            self.send_event(callback, {
                "success": False,
                "error": last_error or "AI ç”Ÿæˆå¤±æ•—",
                "text": None
            })
            
    except Exception as e:
        print(f"[AI] é€šç”¨æ–‡æœ¬ç”ŸæˆéŒ¯èª¤: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        callback = payload.get('callback', 'ai:generate-text-result')
        self.send_event(callback, {
            "success": False,
            "error": str(e),
            "text": None
        })


async def handle_ai_generate_group_names(self, payload: Dict[str, Any]):
    """AI ç”Ÿæˆç¾¤çµ„åç¨±"""
    import sys
    import random
    
    try:
        keywords = payload.get('keywords', '')
        style = payload.get('style', 'professional')
        count = payload.get('count', 5)
        
        print(f"[AI] ç”Ÿæˆç¾¤å: keywords={keywords}, style={style}", file=sys.stderr)
        
        # æ ¹æ“šé¢¨æ ¼å’Œé—œéµè©ç”Ÿæˆç¾¤å
        prefixes = {
            'professional': ['ğŸ¢', 'ğŸ’¼', 'ğŸ“Š', 'ğŸ¯', 'âš¡'],
            'lively': ['ğŸ”¥', 'ğŸ‰', 'âœ¨', 'ğŸ’«', 'ğŸŒŸ'],
            'mysterious': ['ğŸŒ™', 'ğŸ’', 'ğŸ”®', 'ğŸ‘‘', 'ğŸ­'],
            'simple': ['ğŸ“Œ', 'ğŸ“', 'ğŸ”—', 'â€¢', 'â†’']
        }
        
        suffixes = {
            'professional': ['äº¤æµç¾¤', 'ç ”è¨æœƒ', 'ç²¾è‹±ç¤¾', 'è¯ç›Ÿ', 'å•†å‹™åœˆ'],
            'lively': ['å—¨çš®ç¾¤', 'æ­¡æ¨‚ç‡Ÿ', 'ç‹‚æ­¡æ´¾', 'è¶´é«”', 'å¿«æ¨‚å±‹'],
            'mysterious': ['å…§éƒ¨ç¾¤', 'VIPå°ˆå±¬', 'ç§å¯†åœˆ', 'ç§˜å¯†åŸºåœ°', 'æ ¸å¿ƒç¾¤'],
            'simple': ['ç¾¤', 'äº¤æµ', 'è¨è«–çµ„', 'ç¤¾å€', 'é »é“']
        }
        
        prefix_list = prefixes.get(style, prefixes['professional'])
        suffix_list = suffixes.get(style, suffixes['professional'])
        
        names = []
        keyword_parts = [k.strip() for k in keywords.split(',') if k.strip()]
        main_keyword = keyword_parts[0] if keyword_parts else 'äº¤æµ'
        
        for i in range(count):
            prefix = prefix_list[i % len(prefix_list)]
            suffix = suffix_list[i % len(suffix_list)]
            
            # ç”Ÿæˆä¸åŒçµ„åˆ
            if i == 0:
                name = f"{prefix} {main_keyword}{suffix}"
            elif i == 1:
                name = f"{prefix} 2026{main_keyword}ç²¾è‹±{suffix}"
            elif i == 2:
                year_suffix = ['ä¿±æ¨‚éƒ¨', 'è¯ç›Ÿ', 'åœˆå­'][i % 3]
                name = f"{prefix} {main_keyword}{year_suffix}"
            elif i == 3:
                name = f"{prefix} {main_keyword}æ„›å¥½è€…{suffix}"
            else:
                name = f"{prefix} {main_keyword}é”äºº{suffix}"
            
            names.append(name)
        
        self.send_event("ai-generate-group-names-result", {
            "success": True,
            "names": names
        })
        
    except Exception as e:
        print(f"[AI] ç”Ÿæˆç¾¤åå¤±æ•—: {e}", file=sys.stderr)
        self.send_event("ai-generate-group-names-result", {
            "success": False,
            "error": str(e)
        })


async def handle_ai_generate_welcome(self, payload: Dict[str, Any]):
    """AI ç”Ÿæˆæ­¡è¿æ¶ˆæ¯"""
    import sys
    import random
    
    try:
        topic = payload.get('topic', 'æ­¡è¿')
        group_name = payload.get('groupName', 'æˆ‘å€‘çš„ç¾¤çµ„')
        
        print(f"[AI] ç”Ÿæˆæ­¡è¿æ¶ˆæ¯: topic={topic}, group={group_name}", file=sys.stderr)
        
        # æ­¡è¿æ¶ˆæ¯æ¨¡æ¿
        templates = [
            f"ğŸ‰ æ­¡è¿ {{name}} åŠ å…¥ã€Œ{group_name}ã€ï¼å¾ˆé«˜èˆˆèªè­˜ä½ ï¼Œæœ‰ä»»ä½•å•é¡Œéš¨æ™‚æå•å“¦~",
            f"ğŸ‘‹ Hi {{name}}ï¼æ­¡è¿ä¾†åˆ°ã€Œ{group_name}ã€ï¼å¸Œæœ›ä½ åœ¨é€™è£¡èƒ½æ‰¾åˆ°å¿—åŒé“åˆçš„æœ‹å‹ï¼",
            f"âœ¨ {{name}} ä½ å¥½ï¼æ­¡è¿åŠ å…¥æˆ‘å€‘ï¼é€™è£¡æ˜¯ã€Œ{group_name}ã€ï¼Œå¤§å®¶éƒ½å¾ˆå‹å–„çš„~",
            f"ğŸŒŸ ç†±çƒˆæ­¡è¿ {{name}}ï¼ã€Œ{group_name}ã€åˆå¤šäº†ä¸€ä½å°å¤¥ä¼´ï¼",
            f"ğŸ’« {{name}} æ­¡è¿å…¥ç¾¤ï¼ã€Œ{group_name}ã€æœŸå¾…èˆ‡ä½ ä¸€èµ·æˆé•·ï¼"
        ]
        
        message = random.choice(templates)
        
        self.send_event("ai-generate-welcome-result", {
            "success": True,
            "message": message
        })
        
    except Exception as e:
        print(f"[AI] ç”Ÿæˆæ­¡è¿æ¶ˆæ¯å¤±æ•—: {e}", file=sys.stderr)
        self.send_event("ai-generate-welcome-result", {
            "success": False,
            "error": str(e)
        })


# ==================== Local AI & Voice Services Handlers ====================

async def handle_test_local_ai(self, payload: Dict[str, Any]):
    """Test connection to local AI service with detailed diagnostics"""
    import aiohttp
    import socket
    import time
    from urllib.parse import urlparse
    
    endpoint = payload.get('endpoint', 'http://localhost:3002')
    model = payload.get('model', '')
    
    diagnostics = {
        "endpoint": endpoint,
        "tcp_connection": False,
        "http_connection": False,
        "ai_response": False,
        "errors": []
    }
    
    try:
        # è§£æç«¯é»
        parsed = urlparse(endpoint)
        host = parsed.hostname
        port = parsed.port or (443 if parsed.scheme == 'https' else 80)
        
        print(f"[AI Test] Testing connection to {host}:{port}...", file=sys.stderr)
        
        # æ­¥é©Ÿ 1: æ¸¬è©¦ TCP é€£æ¥
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex((host, port))
            sock.close()
            
            if result == 0:
                diagnostics["tcp_connection"] = True
                print(f"[AI Test] âœ“ TCP connection to {host}:{port} successful", file=sys.stderr)
            else:
                diagnostics["errors"].append(f"TCP é€£æ¥å¤±æ•— (éŒ¯èª¤ä»£ç¢¼: {result})")
                print(f"[AI Test] âœ— TCP connection failed (error code: {result})", file=sys.stderr)
                self.send_event("local-ai-test-result", {
                    "success": False,
                    "endpoint": endpoint,
                    "diagnostics": diagnostics,
                    "error": f"ç„¡æ³•é€£æ¥åˆ° {host}:{port}ã€‚è«‹æª¢æŸ¥ï¼š\n1. AI æœå‹™æ˜¯å¦æ­£åœ¨é‹è¡Œ\n2. é˜²ç«ç‰†æ˜¯å¦å…è¨±é€£æ¥\n3. ç¶²çµ¡æ˜¯å¦æ­£å¸¸"
                })
                return
        except socket.gaierror as e:
            diagnostics["errors"].append(f"DNS è§£æå¤±æ•—: {str(e)}")
            print(f"[AI Test] âœ— DNS resolution failed: {e}", file=sys.stderr)
            self.send_event("local-ai-test-result", {
                "success": False,
                "endpoint": endpoint,
                "diagnostics": diagnostics,
                "error": f"ç„¡æ³•è§£æä¸»æ©Ÿå {host}ã€‚è«‹æª¢æŸ¥ç¶²çµ¡è¨­ç½®"
            })
            return
        except socket.timeout:
            diagnostics["errors"].append("TCP é€£æ¥è¶…æ™‚")
            print(f"[AI Test] âœ— TCP connection timeout", file=sys.stderr)
            self.send_event("local-ai-test-result", {
                "success": False,
                "endpoint": endpoint,
                "diagnostics": diagnostics,
                "error": f"é€£æ¥ {host}:{port} è¶…æ™‚ã€‚è«‹æª¢æŸ¥é˜²ç«ç‰†è¨­ç½®"
            })
            return
        except Exception as e:
            diagnostics["errors"].append(f"TCP é€£æ¥éŒ¯èª¤: {str(e)}")
            print(f"[AI Test] âœ— TCP connection error: {e}", file=sys.stderr)
        
        # æ­¥é©Ÿ 2: æ¸¬è©¦ HTTP é€£æ¥
        timeout = aiohttp.ClientTimeout(total=30, connect=5)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            # å˜—è©¦ GET è«‹æ±‚ï¼ˆOllama å¥åº·æª¢æŸ¥ï¼‰
            try:
                health_url = endpoint.rstrip('/')
                if not health_url.endswith('/api/tags') and not health_url.endswith('/v1/models'):
                    # å˜—è©¦ Ollama å¥åº·æª¢æŸ¥ç«¯é»
                    health_endpoints = [
                        f"{health_url}",
                        f"{health_url}/api/tags",
                        f"{health_url}/v1/models"
                    ]
                else:
                    health_endpoints = [health_url]
                
                for health_endpoint in health_endpoints:
                    try:
                        async with session.get(health_endpoint, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                            if resp.status in [200, 404, 405]:
                                diagnostics["http_connection"] = True
                                print(f"[AI Test] âœ“ HTTP connection successful: {health_endpoint} (status: {resp.status})", file=sys.stderr)
                                break
                    except:
                        continue
            except Exception as e:
                diagnostics["errors"].append(f"HTTP é€£æ¥æ¸¬è©¦å¤±æ•—: {str(e)}")
                print(f"[AI Test] HTTP connection test failed: {e}", file=sys.stderr)
            
            # æ­¥é©Ÿ 3: æ¸¬è©¦å¯¦éš› AI è«‹æ±‚
            try:
                chat_url = endpoint.rstrip('/')
                if not chat_url.endswith('/v1/chat/completions'):
                    chat_url = chat_url.rstrip('/') + '/v1/chat/completions'
                
                test_payload = {
                    "messages": [{"role": "user", "content": "test"}],
                    "max_tokens": 10
                }
                if model:
                    test_payload["model"] = model
                
                print(f"[AI Test] Testing AI request to {chat_url}...", file=sys.stderr)
                start_time = time.time()
                
                async with session.post(chat_url, json=test_payload, timeout=aiohttp.ClientTimeout(total=30)) as resp:
                    elapsed = time.time() - start_time
                    print(f"[AI Test] Response received in {elapsed:.2f}s, status: {resp.status}", file=sys.stderr)
                    
                    if resp.status == 200:
                        data = await resp.json()
                        if 'choices' in data or 'response' in data or 'content' in data:
                            diagnostics["ai_response"] = True
                            print(f"[AI Test] âœ“ AI service responded successfully", file=sys.stderr)
                            self.send_event("local-ai-test-result", {
                                "success": True,
                                "endpoint": endpoint,
                                "diagnostics": diagnostics,
                                "response_time": elapsed
                            })
                            self.send_log(f"âœ“ æœ¬åœ° AI é€£æ¥æˆåŠŸ: {endpoint} (éŸ¿æ‡‰æ™‚é–“: {elapsed:.2f}ç§’)", "success")
                            return
                        else:
                            diagnostics["errors"].append(f"AI éŸ¿æ‡‰æ ¼å¼ç•°å¸¸: {list(data.keys())}")
                    else:
                        error_text = await resp.text()
                        diagnostics["errors"].append(f"HTTP {resp.status}: {error_text[:200]}")
                        print(f"[AI Test] âœ— AI service returned error: {resp.status}", file=sys.stderr)
                        
            except asyncio.TimeoutError:
                elapsed = time.time() - start_time if 'start_time' in locals() else 30
                diagnostics["errors"].append(f"AI è«‹æ±‚è¶…æ™‚ ({elapsed:.1f}ç§’)")
                print(f"[AI Test] âœ— AI request timeout after {elapsed:.2f}s", file=sys.stderr)
            except aiohttp.ClientConnectorError as e:
                diagnostics["errors"].append(f"ç„¡æ³•é€£æ¥åˆ°ç«¯é»: {str(e)}")
                print(f"[AI Test] âœ— Connection error: {e}", file=sys.stderr)
            except Exception as e:
                diagnostics["errors"].append(f"AI è«‹æ±‚éŒ¯èª¤: {str(e)}")
                print(f"[AI Test] âœ— AI request error: {e}", file=sys.stderr)
        
        # å¦‚æœæ‰€æœ‰æ¸¬è©¦éƒ½å¤±æ•—
        self.send_event("local-ai-test-result", {
            "success": False,
            "endpoint": endpoint,
            "diagnostics": diagnostics,
            "error": f"ç„¡æ³•é€£æ¥åˆ°æœ¬åœ° AI æœå‹™ã€‚è¨ºæ–·ä¿¡æ¯ï¼š\n" + "\n".join(diagnostics["errors"])
        })
        self.send_log(f"âœ— æœ¬åœ° AI é€£æ¥å¤±æ•—: {endpoint}", "error")
            
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[AI Test] Unexpected error: {error_details}", file=sys.stderr)
        diagnostics["errors"].append(f"æœªé æœŸçš„éŒ¯èª¤: {str(e)}")
        self.send_event("local-ai-test-result", {
            "success": False,
            "endpoint": endpoint,
            "diagnostics": diagnostics,
            "error": str(e)
        })
        self.send_log(f"âœ— æœ¬åœ° AI æ¸¬è©¦éŒ¯èª¤: {str(e)}", "error")


async def handle_test_tts_service(self, payload: Dict[str, Any]):
    """Test connection to TTS service (GPT-SoVITS) - ğŸ”§ P2 å„ªåŒ–ï¼šçœŸæ­£çš„èªéŸ³ç”Ÿæˆæ¸¬è©¦"""
    import time as time_module
    endpoint = payload.get('endpoint', 'http://localhost:9881')
    
    diagnostics = {
        "endpoint": endpoint,
        "http_reachable": False,
        "tts_available": False,
        "voice_generation": False,
        "latency_ms": 0,
        "errors": []
    }
    
    try:
        import aiohttp
        start_time = time_module.time()
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
            # æ­¥é©Ÿ 1: æ¸¬è©¦ HTTP å¯é”æ€§
            try:
                async with session.get(f"{endpoint}/") as resp:
                    if resp.status in [200, 404, 405]:
                        diagnostics["http_reachable"] = True
                        print(f"[TTS Test] âœ“ HTTP å¯é”", file=sys.stderr)
            except Exception as e:
                diagnostics["errors"].append(f"HTTP é€£æ¥å¤±æ•—: {str(e)}")
                print(f"[TTS Test] âœ— HTTP é€£æ¥å¤±æ•—: {e}", file=sys.stderr)
            
            # æ­¥é©Ÿ 2: å˜—è©¦ç²å– TTS æœå‹™ç‹€æ…‹/å¯ç”¨èªéŸ³åˆ—è¡¨
            tts_api_endpoints = [
                f"{endpoint}/",  # GPT-SoVITS æ ¹ç«¯é»
                f"{endpoint}/tts",
                f"{endpoint}/api/tts",
                f"{endpoint}/v1/audio/speech",  # OpenAI å…¼å®¹
            ]
            
            for api_url in tts_api_endpoints:
                try:
                    async with session.get(api_url, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                        if resp.status in [200, 405]:  # GET å¯èƒ½è¿”å› 405ï¼Œä½†èªªæ˜ç«¯é»å­˜åœ¨
                            diagnostics["tts_available"] = True
                            print(f"[TTS Test] âœ“ TTS API å¯ç”¨: {api_url}", file=sys.stderr)
                            break
                except:
                    continue
            
            # æ­¥é©Ÿ 3: å˜—è©¦çœŸæ­£çš„èªéŸ³ç”Ÿæˆæ¸¬è©¦
            if diagnostics["tts_available"] or diagnostics["http_reachable"]:
                test_text = "æ¸¬è©¦"
                tts_endpoints = [
                    (f"{endpoint}/", {"text": test_text, "text_language": "zh"}),  # GPT-SoVITS
                    (f"{endpoint}/tts", {"text": test_text}),
                    (f"{endpoint}/api/tts", {"text": test_text}),
                ]
                
                for tts_url, payload_data in tts_endpoints:
                    try:
                        gen_start = time_module.time()
                        async with session.post(tts_url, json=payload_data, timeout=aiohttp.ClientTimeout(total=20)) as resp:
                            if resp.status == 200:
                                content_type = resp.headers.get('content-type', '')
                                if 'audio' in content_type or 'octet-stream' in content_type:
                                    diagnostics["voice_generation"] = True
                                    diagnostics["latency_ms"] = int((time_module.time() - gen_start) * 1000)
                                    print(f"[TTS Test] âœ“ èªéŸ³ç”ŸæˆæˆåŠŸï¼Œå»¶é²: {diagnostics['latency_ms']}ms", file=sys.stderr)
                                    break
                                else:
                                    # å¯èƒ½è¿”å› JSON éŒ¯èª¤
                                    try:
                                        data = await resp.json()
                                        if 'audio' in data or 'wav' in str(data):
                                            diagnostics["voice_generation"] = True
                                            diagnostics["latency_ms"] = int((time_module.time() - gen_start) * 1000)
                                            break
                                    except:
                                        pass
                    except asyncio.TimeoutError:
                        diagnostics["errors"].append(f"èªéŸ³ç”Ÿæˆè¶…æ™‚")
                    except Exception as e:
                        # ç¹¼çºŒå˜—è©¦å…¶ä»–ç«¯é»
                        continue
            
            # è¨ˆç®—ç¸½å»¶é²
            total_latency = int((time_module.time() - start_time) * 1000)
            if diagnostics["latency_ms"] == 0:
                diagnostics["latency_ms"] = total_latency
            
            # åˆ¤æ–·æˆåŠŸæ¨™æº–
            if diagnostics["voice_generation"]:
                self.send_event("tts-test-result", {
                    "success": True,
                    "endpoint": endpoint,
                    "diagnostics": diagnostics,
                    "latencyMs": diagnostics["latency_ms"],
                    "message": f"èªéŸ³æœå‹™æ­£å¸¸ï¼Œç”Ÿæˆå»¶é² {diagnostics['latency_ms']}ms"
                })
                self.send_log(f"âœ“ TTS æœå‹™å®Œå…¨æ­£å¸¸: {endpoint} (å»¶é²: {diagnostics['latency_ms']}ms)", "success")
            elif diagnostics["tts_available"] or diagnostics["http_reachable"]:
                self.send_event("tts-test-result", {
                    "success": True,
                    "endpoint": endpoint,
                    "diagnostics": diagnostics,
                    "latencyMs": total_latency,
                    "message": "æœå‹™å¯é”ï¼Œä½†ç„¡æ³•é©—è­‰èªéŸ³ç”Ÿæˆï¼ˆå¯èƒ½éœ€è¦é…ç½®èªéŸ³æ¨¡å‹ï¼‰"
                })
                self.send_log(f"âš  TTS æœå‹™å¯é”ä½†æœªé©—è­‰èªéŸ³ç”Ÿæˆ: {endpoint}", "warning")
            else:
                self.send_event("tts-test-result", {
                    "success": False,
                    "endpoint": endpoint,
                    "diagnostics": diagnostics,
                    "error": "ç„¡æ³•é€£æ¥åˆ° TTS æœå‹™\n" + "\n".join(diagnostics["errors"])
                })
                self.send_log(f"âœ— TTS æœå‹™é€£æ¥å¤±æ•—: {endpoint}", "error")
            
    except Exception as e:
        import traceback
        print(f"[TTS Test] ç•°å¸¸: {traceback.format_exc()}", file=sys.stderr)
        self.send_event("tts-test-result", {
            "success": False,
            "endpoint": endpoint,
            "diagnostics": diagnostics,
            "error": str(e)
        })
        self.send_log(f"âœ— TTS æ¸¬è©¦éŒ¯èª¤: {str(e)}", "error")


async def handle_test_stt_service(self, payload: Dict[str, Any]):
    """Test connection to STT service (Whisper)"""
    endpoint = payload.get('endpoint', 'http://localhost:9000')
    
    try:
        import aiohttp
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
            test_urls = [
                f"{endpoint}/",
                f"{endpoint}/transcribe",
                f"{endpoint}/api/transcribe",
            ]
            
            for test_url in test_urls:
                try:
                    async with session.get(test_url) as response:
                        if response.status in [200, 404, 405]:
                            self.send_event("stt-test-result", {
                                "success": True,
                                "endpoint": endpoint,
                                "status": response.status
                            })
                            self.send_log(f"âœ“ STT æœå‹™é€£æ¥æˆåŠŸ: {endpoint}", "success")
                            return
                except:
                    continue
            
            self.send_event("stt-test-result", {
                "success": False,
                "endpoint": endpoint,
                "error": "ç„¡æ³•é€£æ¥åˆ° STT æœå‹™"
            })
            self.send_log(f"âœ— STT æœå‹™é€£æ¥å¤±æ•—: {endpoint}", "error")
            
    except Exception as e:
        self.send_event("stt-test-result", {
            "success": False,
            "endpoint": endpoint,
            "error": str(e)
        })
        self.send_log(f"âœ— STT æ¸¬è©¦éŒ¯èª¤: {str(e)}", "error")


async def handle_get_ai_settings(self, payload: Dict[str, Any] = None):
    """ç²å– AI è¨­ç½®ï¼ˆåŒ…æ‹¬ Gemini API Keyï¼‰"""
    try:
        # å¾æ•¸æ“šåº«ç²å–è¨­ç½®
        settings = await db.get_ai_settings()
        
        result = {
            'geminiApiKey': settings.get('gemini_api_key', ''),
            'localAiEndpoint': settings.get('local_ai_endpoint', 'http://localhost:11434'),
            'localAiModel': settings.get('local_ai_model', ''),
            'apiType': settings.get('api_type', 'gemini'),
        }
        
        self.send_event("ai-settings-loaded", result)
        
    except Exception as e:
        import sys
        print(f"[Backend] Error loading AI settings: {e}", file=sys.stderr)
        self.send_event("ai-settings-loaded", {})


async def handle_save_ai_settings(self, payload: Dict[str, Any]):
    """Save AI and voice service settings"""
    try:
        # Store settings in memory (for legacy compatibility)
        settings = {
            "apiType": payload.get('apiType', 'gemini'),
            "apiKey": payload.get('apiKey', ''),
            "endpoint": payload.get('endpoint', ''),
            "localAiEndpoint": payload.get('localAiEndpoint', 'http://localhost:3002'),
            "localAiModel": payload.get('localAiModel', ''),
            "ttsEndpoint": payload.get('ttsEndpoint', 'http://localhost:9881'),
            "ttsEnabled": payload.get('ttsEnabled', False),
            "ttsVoice": payload.get('ttsVoice', ''),
            "sttEndpoint": payload.get('sttEndpoint', 'http://localhost:9000'),
            "sttEnabled": payload.get('sttEnabled', False)
        }
        
        # Store in self for later use
        self.ai_settings = settings
        
        # ğŸ”§ é—œéµä¿®å¾©ï¼šåŒæ™‚ä¿å­˜åˆ°æ•¸æ“šåº«ï¼ˆä½¿ç”¨ snake_case éµåï¼‰
        db_settings = {
            'local_ai_endpoint': payload.get('localAiEndpoint', ''),
            'local_ai_model': payload.get('localAiModel', ''),
            'gemini_api_key': payload.get('geminiApiKey', ''),  # æ·»åŠ  Gemini API Key ä¿å­˜
            'api_type': payload.get('apiType', 'gemini'),
        }
        await db.update_ai_settings(db_settings)
        
        # é‡æ–°è¼‰å…¥ AI æœå‹™è¨­ç½®
        await ai_auto_chat.initialize()
        
        # è¨­ç½® AI é…ç½®
        endpoint = payload.get('localAiEndpoint', '')
        model = payload.get('localAiModel', '')
        if endpoint:
            ai_auto_chat.set_ai_config(endpoint, model)
            self.send_log(f"âœ“ AI ç«¯é»å·²é…ç½®: {endpoint}", "success")
        
        self.send_event("ai-settings-saved", {"success": True})
        self.send_log("AI å’ŒèªéŸ³æœå‹™è¨­ç½®å·²ä¿å­˜åˆ°æ•¸æ“šåº«", "success")
        
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        self.send_event("ai-settings-saved", {"success": False, "error": str(e)})
        self.send_log(f"ä¿å­˜ AI è¨­ç½®å¤±æ•—: {str(e)}", "error")


async def handle_set_autonomous_mode(self, payload: Dict[str, Any]):
    """ğŸ†• è¨­ç½® AI è‡ªä¸»æ¨¡å¼é–‹é—œ"""
    enabled = payload.get('enabled', False)
    
    try:
        # ä¿å­˜åˆ°æ•¸æ“šåº«
        await db.execute("""
            INSERT INTO ai_settings (key, value) VALUES ('autonomous_mode', ?)
            ON CONFLICT(key) DO UPDATE SET value = excluded.value, updated_at = CURRENT_TIMESTAMP
        """, ('1' if enabled else '0',))
        
        # æ›´æ–° AI æœå‹™
        if ai_auto_chat:
            ai_auto_chat.autonomous_mode = enabled
            self.send_log(f"AI è‡ªä¸»æ¨¡å¼å·²{'å•Ÿç”¨' if enabled else 'é—œé–‰'}", "success")
        
        self.send_event("autonomous-mode-updated", {
            "success": True,
            "enabled": enabled
        })
        
    except Exception as e:
        print(f"[Backend] Error setting autonomous mode: {e}", file=sys.stderr)
        self.send_event("autonomous-mode-updated", {
            "success": False,
            "error": str(e)
        })


async def handle_generate_with_local_ai(self, payload: Dict[str, Any]):
    """Generate text using local AI service"""
    endpoint = payload.get('endpoint', getattr(self, 'ai_settings', {}).get('localAiEndpoint', 'http://localhost:3002'))
    prompt = payload.get('prompt', '')
    model = payload.get('model', '')
    
    try:
        import aiohttp
        
        # Try OpenAI-compatible API format
        request_data = {
            "model": model or "default",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 500,
            "temperature": 0.7
        }
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
            async with session.post(f"{endpoint}/v1/chat/completions", json=request_data) as response:
                if response.status == 200:
                    result = await response.json()
                    generated_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                    
                    self.send_event("local-ai-generation-result", {
                        "success": True,
                        "text": generated_text
                    })
                    return
                else:
                    error_text = await response.text()
                    self.send_event("local-ai-generation-result", {
                        "success": False,
                        "error": f"API è¿”å› {response.status}: {error_text}"
                    })
                    
    except Exception as e:
        self.send_event("local-ai-generation-result", {
            "success": False,
            "error": str(e)
        })


async def handle_summarize_conversation(self, payload: Dict[str, Any]):
    """ç”Ÿæˆå°è©±æ‘˜è¦"""
    try:
        user_id = payload.get('userId', '')
        max_messages = payload.get('maxMessages', 50)
        
        result = await vector_memory.summarize_conversation(
            user_id=user_id,
            max_messages=max_messages
        )
        
        self.send_event("conversation-summarized", result)
    except Exception as e:
        self.send_event("conversation-summarized", {
            "success": False,
            "error": str(e)
        })


async def handle_ai_analyze_interest(self, payload: Dict[str, Any]):
    """AI åˆ†æèˆˆè¶£ä¿¡è™Ÿ"""
    import sys
    
    try:
        from automation_workflow import get_automation_workflow_service
        
        service = get_automation_workflow_service()
        result = await service.handle_analyze_interest(payload)
        
        self.send_event("ai:analyze-interest-result", result)
        print(f"[AutomationWorkflow] èˆˆè¶£åˆ†æ: hasInterest={result.get('hasInterest')}", file=sys.stderr)
        
    except Exception as e:
        print(f"[AutomationWorkflow] èˆˆè¶£åˆ†æéŒ¯èª¤: {e}", file=sys.stderr)
        self.send_event("ai:analyze-interest-result", {"success": False, "error": str(e)})


# ============ ğŸ†• AI Team åŸ·è¡Œç›¸é—œ ============

async def handle_ai_execution_save(self, payload: Dict[str, Any]):
    """ğŸ”§ Phase 4: æŒä¹…åŒ– AI åŸ·è¡Œç‹€æ…‹åˆ°æ•¸æ“šåº«"""
    import sys
    
    try:
        execution_id = payload.get('id')
        if not execution_id:
            return
        
        # ç¢ºä¿è¡¨å­˜åœ¨
        await db.execute("""
            CREATE TABLE IF NOT EXISTS ai_executions (
                id TEXT PRIMARY KEY,
                execution_type TEXT NOT NULL,
                status TEXT DEFAULT 'running',
                mode TEXT,
                goal TEXT,
                target_users TEXT,
                role_accounts TEXT,
                group_id TEXT,
                group_name TEXT,
                message_history TEXT DEFAULT '[]',
                stats TEXT DEFAULT '{}',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                completed_at TIMESTAMP
            )
        """)
        
        # æ’å…¥æˆ–æ›´æ–°
        await db.execute("""
            INSERT OR REPLACE INTO ai_executions 
            (id, execution_type, status, mode, goal, target_users, role_accounts, 
             group_id, group_name, message_history, stats, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (
            execution_id,
            payload.get('executionType', 'private'),
            payload.get('status', 'running'),
            payload.get('mode', 'hybrid'),
            payload.get('goal', ''),
            payload.get('targetUsers', '[]'),
            payload.get('roleAccounts', '[]'),
            payload.get('groupId'),
            payload.get('groupName'),
            payload.get('messageHistory', '[]'),
            payload.get('stats', '{}')
        ))
        
        print(f"[AIExecution] âœ“ å·²ä¿å­˜åŸ·è¡Œç‹€æ…‹: {execution_id}", file=sys.stderr)
        
    except Exception as e:
        print(f"[AIExecution] ä¿å­˜åŸ·è¡Œç‹€æ…‹å¤±æ•—: {e}", file=sys.stderr)


async def handle_ai_execution_get_active(self, payload: Dict[str, Any]):
    """ğŸ”§ Phase 4: ç²å–æ´»èºçš„ AI åŸ·è¡Œä»»å‹™"""
    import sys
    
    try:
        executions = []
        
        # ç¢ºä¿è¡¨å­˜åœ¨
        try:
            cursor = await db.execute("""
                SELECT * FROM ai_executions 
                WHERE status IN ('running', 'executing', 'paused')
                ORDER BY updated_at DESC
                LIMIT 10
            """)
            rows = await cursor.fetchall()
            
            for row in rows:
                executions.append({
                    'id': row['id'],
                    'executionType': row['execution_type'],
                    'status': row['status'],
                    'mode': row['mode'],
                    'goal': row['goal'],
                    'targetUsers': row['target_users'],
                    'roleAccounts': row['role_accounts'],
                    'groupId': row['group_id'],
                    'groupName': row['group_name'],
                    'messageHistory': row['message_history'],
                    'stats': row['stats']
                })
            
            print(f"[AIExecution] æ‰¾åˆ° {len(executions)} å€‹æ´»èºåŸ·è¡Œ", file=sys.stderr)
            
        except Exception as query_err:
            if 'no such table' not in str(query_err).lower():
                print(f"[AIExecution] æŸ¥è©¢å¤±æ•—: {query_err}", file=sys.stderr)
        
        # ğŸ”§ ç™¼é€äº‹ä»¶è¿”å›çµæœ
        self.send_event("ai-execution:active-list", {"executions": executions})
        
    except Exception as e:
        print(f"[AIExecution] ç²å–æ´»èºåŸ·è¡Œå¤±æ•—: {e}", file=sys.stderr)
        self.send_event("ai-execution:active-list", {"executions": [], "error": str(e)})
        return {"executions": [], "error": str(e)}

