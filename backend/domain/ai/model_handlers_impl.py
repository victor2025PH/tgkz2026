"""
Extracted handler implementations: ai_models
Auto-generated by refactor_main.py
"""
import json
import sys
import time
import asyncio
import traceback
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from service_context import get_service_context
from database import db

# All handlers receive (self, payload) where self is BackendService instance.
# They are called via: await handler_impl(self, payload)
# Inside, use self.db, self.send_event(), self.telegram_manager, etc.
# This is a transitional pattern - later, replace self.xxx with ctx.xxx


# ==================== AI Model Configuration Handlers ====================

async def handle_save_ai_model(self, payload: Dict[str, Any]):
    """ä¿å­˜ AI æ¨¡å‹é…ç½®åˆ°æ•¸æ“šåº«"""
    try:
        provider = payload.get('provider', '')
        model_name = payload.get('modelName', '')
        display_name = payload.get('displayName', model_name)
        api_key = payload.get('apiKey', '')
        api_endpoint = payload.get('apiEndpoint', '')
        is_local = 1 if payload.get('isLocal', False) else 0
        is_default = 1 if payload.get('isDefault', False) else 0
        priority = payload.get('priority', 0)
        config_json = json.dumps(payload.get('config', {}))
        
        if not provider or not model_name:
            self.send_event("ai-model-saved", {
                "success": False,
                "error": "ä¾›æ‡‰å•†å’Œæ¨¡å‹åç¨±ä¸èƒ½ç‚ºç©º"
            })
            return
        
        # å¦‚æœè¨­ç‚ºé»˜èªï¼Œå…ˆå–æ¶ˆå…¶ä»–é»˜èª
        if is_default:
            await db.execute("UPDATE ai_models SET is_default = 0")
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = await db.fetch_one(
            "SELECT id FROM ai_models WHERE provider = ? AND model_name = ?",
            (provider, model_name)
        )
        
        if existing:
            # æ›´æ–°ç¾æœ‰è¨˜éŒ„
            await db.execute(
                """UPDATE ai_models SET 
                   display_name = ?, api_key = ?, api_endpoint = ?, 
                   is_local = ?, is_default = ?, priority = ?, config_json = ?,
                   updated_at = CURRENT_TIMESTAMP
                   WHERE id = ?""",
                (display_name, api_key, api_endpoint, is_local, is_default, priority, config_json, existing['id'])
            )
            model_id = existing['id']
        else:
            # æ’å…¥æ–°è¨˜éŒ„
            await db.execute(
                """INSERT INTO ai_models 
                   (provider, model_name, display_name, api_key, api_endpoint, 
                    is_local, is_default, priority, config_json, created_at, updated_at)
                   VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)""",
                (provider, model_name, display_name, api_key, api_endpoint, 
                 is_local, is_default, priority, config_json)
            )
            model_id = (await db.fetch_one("SELECT last_insert_rowid() as id"))['id']
        
        self.send_log(f"âœ… AI æ¨¡å‹å·²ä¿å­˜: {display_name} ({provider})", "success")
        self.send_event("ai-model-saved", {
            "success": True,
            "modelId": model_id,
            "provider": provider,
            "modelName": model_name
        })
        
        # åŒæ™‚ç™¼é€æ›´æ–°å¾Œçš„æ¨¡å‹åˆ—è¡¨
        await self.handle_get_ai_models()
        
    except Exception as e:
        self.send_log(f"âŒ ä¿å­˜ AI æ¨¡å‹å¤±æ•—: {e}", "error")
        self.send_event("ai-model-saved", {"success": False, "error": str(e)})


async def handle_get_ai_models(self):
    """ç²å–æ‰€æœ‰å·²ä¿å­˜çš„ AI æ¨¡å‹é…ç½®"""
    try:
        models = await db.fetch_all(
            """SELECT id, provider, model_name, display_name, api_key, api_endpoint,
               is_local, is_default, priority, is_connected, last_tested_at, config_json,
               created_at, updated_at
               FROM ai_models ORDER BY is_default DESC, priority DESC, created_at DESC"""
        )
        
        result = []
        for model in models:
            # éš±è— API Key çš„å¤§éƒ¨åˆ†å…§å®¹
            api_key = model.get('api_key', '') or ''
            masked_key = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else '***'
            
            result.append({
                "id": model['id'],
                "provider": model['provider'],
                "modelName": model['model_name'],
                "displayName": model['display_name'] or model['model_name'],
                "apiKey": api_key,  # å®Œæ•´ key ç”¨æ–¼å‰ç«¯ä½¿ç”¨
                "apiKeyMasked": masked_key,  # é¡¯ç¤ºç”¨
                "apiEndpoint": model['api_endpoint'],
                "isLocal": bool(model['is_local']),
                "isDefault": bool(model['is_default']),
                "priority": model['priority'],
                "isConnected": bool(model['is_connected']),
                "lastTestedAt": model['last_tested_at'],
                "config": json.loads(model['config_json'] or '{}'),
                "createdAt": model['created_at'],
                "updatedAt": model['updated_at']
            })
        
        self.send_event("ai-models-list", {
            "success": True,
            "models": result,
            "count": len(result)
        })
        
    except Exception as e:
        self.send_log(f"âŒ ç²å– AI æ¨¡å‹åˆ—è¡¨å¤±æ•—: {e}", "error")
        self.send_event("ai-models-list", {"success": False, "error": str(e), "models": []})


async def handle_update_ai_model(self, payload: Dict[str, Any]):
    """æ›´æ–° AI æ¨¡å‹é…ç½®"""
    try:
        model_id = payload.get('id')
        if not model_id:
            self.send_event("ai-model-updated", {"success": False, "error": "ç¼ºå°‘æ¨¡å‹ ID"})
            return
        
        updates = []
        params = []
        
        if 'displayName' in payload:
            updates.append("display_name = ?")
            params.append(payload['displayName'])
        if 'apiKey' in payload:
            updates.append("api_key = ?")
            params.append(payload['apiKey'])
        if 'apiEndpoint' in payload:
            updates.append("api_endpoint = ?")
            params.append(payload['apiEndpoint'])
        if 'isDefault' in payload:
            if payload['isDefault']:
                await db.execute("UPDATE ai_models SET is_default = 0")
            updates.append("is_default = ?")
            params.append(1 if payload['isDefault'] else 0)
        if 'priority' in payload:
            updates.append("priority = ?")
            params.append(payload['priority'])
        if 'isConnected' in payload:
            updates.append("is_connected = ?")
            params.append(1 if payload['isConnected'] else 0)
            updates.append("last_tested_at = CURRENT_TIMESTAMP")
        
        if updates:
            updates.append("updated_at = CURRENT_TIMESTAMP")
            params.append(model_id)
            await db.execute(
                f"UPDATE ai_models SET {', '.join(updates)} WHERE id = ?",
                tuple(params)
            )
        
        self.send_event("ai-model-updated", {"success": True, "modelId": model_id})
        await self.handle_get_ai_models()
        
    except Exception as e:
        self.send_event("ai-model-updated", {"success": False, "error": str(e)})


async def handle_delete_ai_model(self, payload: Dict[str, Any]):
    """åˆªé™¤ AI æ¨¡å‹é…ç½®"""
    try:
        model_id = payload.get('id')
        if not model_id:
            self.send_event("ai-model-deleted", {"success": False, "error": "ç¼ºå°‘æ¨¡å‹ ID"})
            return
        
        await db.execute("DELETE FROM ai_models WHERE id = ?", (model_id,))
        
        self.send_log(f"âœ… AI æ¨¡å‹å·²åˆªé™¤: ID={model_id}", "success")
        self.send_event("ai-model-deleted", {"success": True, "modelId": model_id})
        await self.handle_get_ai_models()
        
    except Exception as e:
        self.send_event("ai-model-deleted", {"success": False, "error": str(e)})


async def handle_test_ai_model(self, payload: Dict[str, Any]):
    """æ¸¬è©¦ AI æ¨¡å‹é€£æ¥ - æ”¯æŒå¤šç¨® API æ ¼å¼"""
    try:
        import sys
        model_id = payload.get('id')
        provider = payload.get('provider', '')
        api_key = payload.get('apiKey', '')
        api_endpoint = payload.get('apiEndpoint', '')
        model_name = payload.get('modelName', '')
        is_local = payload.get('isLocal', False)
        
        import time as time_module
        test_start_time = time_module.time()
        
        print(f"[AI Test] é–‹å§‹æ¸¬è©¦: provider={provider}, endpoint={api_endpoint}, model={model_name}, isLocal={is_local}", file=sys.stderr)
        self.send_log(f"ğŸ”— æ­£åœ¨æ¸¬è©¦ AI æ¨¡å‹é€£æ¥: {model_name}...", "info")
        
        is_connected = False
        error_message = None
        response_preview = None
        latency_ms = 0
        
        try:
            if is_local or provider == 'ollama' or provider == 'custom':
                # æ¸¬è©¦æœ¬åœ°/è‡ªå®šç¾© AI - å˜—è©¦å¤šç¨®æ ¼å¼
                import aiohttp
                test_url = api_endpoint or 'http://localhost:11434/api/chat'
                print(f"[AI Test] æ¸¬è©¦ URL: {test_url}", file=sys.stderr)
                
                async with aiohttp.ClientSession() as session:
                    # ğŸ”§ P2 å„ªåŒ–ï¼šå…ˆæŸ¥è©¢å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆåƒ… Ollamaï¼‰
                    available_models = []
                    is_ollama = ':11434' in test_url or '.ts.net' in test_url or provider == 'ollama'
                    if is_ollama:
                        try:
                            tags_url = test_url.rstrip('/').replace('/api/chat', '') + '/api/tags'
                            async with session.get(tags_url, timeout=aiohttp.ClientTimeout(total=5)) as tags_resp:
                                if tags_resp.status == 200:
                                    tags_data = await tags_resp.json()
                                    models = tags_data.get('models', [])
                                    available_models = [m.get('name', '') for m in models[:10]]  # æœ€å¤šé¡¯ç¤º 10 å€‹
                                    print(f"[AI Test] å¯ç”¨æ¨¡å‹: {available_models}", file=sys.stderr)
                        except Exception as e:
                            print(f"[AI Test] ç„¡æ³•ç²å–æ¨¡å‹åˆ—è¡¨: {e}", file=sys.stderr)
                    
                    # é¦–å…ˆå˜—è©¦ OpenAI å…¼å®¹æ ¼å¼
                    try:
                        # ğŸ”§ FIX: æ™ºèƒ½åˆ¤æ–· URL æ ¼å¼
                        # ç¢ºå®š URL æ ¼å¼
                        if '/v1/chat/completions' in test_url:
                            chat_url = test_url
                        elif test_url.endswith('/chat'):
                            # å¯èƒ½æ˜¯ OpenAI å…¼å®¹çš„ /chat ç«¯é»
                            chat_url = test_url
                        elif test_url.endswith('/api/chat'):
                            # Ollama æ ¼å¼
                            chat_url = test_url
                        elif ':11434' in test_url or provider == 'ollama' or '.ts.net' in test_url:
                            # ğŸ”§ FIX: æª¢æ¸¬åˆ° Ollama ç«¯å£æˆ– Tailscale åŸŸåï¼Œä½¿ç”¨ Ollama API æ ¼å¼
                            chat_url = test_url.rstrip('/') + '/api/chat'
                            print(f"[AI Test] æª¢æ¸¬åˆ° Ollama/Tailscale ç«¯é»ï¼Œä½¿ç”¨ /api/chat", file=sys.stderr)
                        else:
                            chat_url = test_url.rstrip('/') + '/v1/chat/completions'
                        
                        headers = {'Content-Type': 'application/json'}
                        if api_key:
                            headers['Authorization'] = f'Bearer {api_key}'
                        
                        # ğŸ”§ FIX: æ ¹æ“šç«¯é»é¡å‹é¸æ“‡è«‹æ±‚æ ¼å¼
                        is_ollama_endpoint = '/api/chat' in chat_url or ':11434' in chat_url or '.ts.net' in chat_url
                        
                        # ğŸ”§ P0 å„ªåŒ–ï¼šä½¿ç”¨æ›´æ˜ç¢ºçš„æ¸¬è©¦æ¶ˆæ¯ï¼Œè¦æ±‚ AI å›è¦†ç‰¹å®šå…§å®¹
                        test_message = "é€™æ˜¯ä¸€å€‹é€£æ¥æ¸¬è©¦ã€‚è«‹å›è¦†ã€Œé€£æ¥æˆåŠŸã€ä¸‰å€‹å­—ã€‚"
                        
                        if is_ollama_endpoint:
                            # Ollama åŸç”Ÿæ ¼å¼
                            request_body = {
                                "model": model_name or "llama3",
                                "messages": [{"role": "user", "content": test_message}],
                                "stream": False,
                                "options": {"num_predict": 50}  # å¢åŠ  token æ•¸é‡ä»¥ç²å¾—å®Œæ•´å›è¦†
                            }
                            print(f"[AI Test] ä½¿ç”¨ Ollama æ ¼å¼: {chat_url}", file=sys.stderr)
                        else:
                            # OpenAI å…¼å®¹æ ¼å¼
                            request_body = {
                                "model": model_name or "default",
                                "messages": [{"role": "user", "content": test_message}],
                                "max_tokens": 50,  # å¢åŠ  token æ•¸é‡
                                "stream": False
                            }
                            print(f"[AI Test] ä½¿ç”¨ OpenAI æ ¼å¼: {chat_url}", file=sys.stderr)
                        async with session.post(
                            chat_url,
                            headers=headers,
                            json=request_body,
                            timeout=aiohttp.ClientTimeout(total=15)
                        ) as resp:
                            print(f"[AI Test] éŸ¿æ‡‰ç‹€æ…‹: {resp.status}", file=sys.stderr)
                            if resp.status == 200:
                                data = await resp.json()
                                # ğŸ”§ P0 å„ªåŒ–ï¼šè¨ˆç®—å»¶é²æ™‚é–“
                                latency_ms = int((time_module.time() - test_start_time) * 1000)
                                
                                # OpenAI æ ¼å¼éŸ¿æ‡‰
                                content = data.get('choices', [{}])[0].get('message', {}).get('content', '')
                                # Ollama æ ¼å¼éŸ¿æ‡‰
                                if not content:
                                    content = data.get('message', {}).get('content', '')
                                # å…¶ä»–æ ¼å¼
                                if not content:
                                    content = data.get('response', '') or data.get('content', '')
                                
                                if content:
                                    is_connected = True
                                    response_preview = content[:100] + ('...' if len(content) > 100 else '')
                                    print(f"[AI Test] âœ“ æˆåŠŸï¼å»¶é²: {latency_ms}msï¼ŒéŸ¿æ‡‰: {response_preview}", file=sys.stderr)
                                else:
                                    # æœ‰éŸ¿æ‡‰ä½†æ²’æœ‰å…§å®¹ï¼Œå¯èƒ½æ ¼å¼ä¸å°
                                    is_connected = True  # è‡³å°‘é€£æ¥æˆåŠŸäº†
                                    response_preview = f"API å¯é” (éŸ¿æ‡‰æ ¼å¼: {list(data.keys())[:3]})"
                                    print(f"[AI Test] âœ“ é€£æ¥æˆåŠŸä½†éŸ¿æ‡‰æ ¼å¼æœªçŸ¥ï¼Œå»¶é²: {latency_ms}ms", file=sys.stderr)
                            else:
                                resp_text = await resp.text()
                                error_message = f"HTTP {resp.status}: {resp_text[:100]}"
                                print(f"[AI Test] å¤±æ•—: {error_message}", file=sys.stderr)
                    except Exception as e1:
                        print(f"[AI Test] OpenAI æ ¼å¼å¤±æ•—: {e1}", file=sys.stderr)
                        
                        # å˜—è©¦ Ollama åŸç”Ÿæ ¼å¼
                        try:
                            ollama_url = api_endpoint or 'http://localhost:11434/api/chat'
                            if not ollama_url.endswith('/api/chat'):
                                ollama_url = ollama_url.rstrip('/') + '/api/chat'
                            
                            print(f"[AI Test] å˜—è©¦ Ollama æ ¼å¼: {ollama_url}", file=sys.stderr)
                            async with session.post(
                                ollama_url,
                                json={
                                    "model": model_name or "qwen2:7b",
                                    "messages": [{"role": "user", "content": "Hi"}],
                                    "stream": False,
                                    "options": {"num_predict": 10}
                                },
                                timeout=aiohttp.ClientTimeout(total=15)
                            ) as resp:
                                if resp.status == 200:
                                    data = await resp.json()
                                    content = data.get('message', {}).get('content', '')
                                    if content:
                                        is_connected = True
                                        response_preview = content[:50]
                                else:
                                    error_message = f"HTTP {resp.status}"
                        except Exception as e2:
                            error_message = f"é€£æ¥å¤±æ•—: {str(e1)[:50]}; {str(e2)[:50]}"
                            print(f"[AI Test] æ‰€æœ‰æ ¼å¼éƒ½å¤±æ•—: {error_message}", file=sys.stderr)
                            
            elif provider == 'openai':
                import aiohttp
                # è‡ªå‹•æ ¼å¼åŒ–æ¨¡å‹åç¨±ï¼ˆè½‰å°å¯«ï¼Œè™•ç†å¸¸è¦‹è®Šé«”ï¼‰
                normalized_model = model_name.lower().strip()
                model_name_map = {
                    'gpt4o': 'gpt-4o',
                    'gpt-4o': 'gpt-4o',
                    'gpt4': 'gpt-4',
                    'gpt-4': 'gpt-4',
                    'gpt4turbo': 'gpt-4-turbo',
                    'gpt-4-turbo': 'gpt-4-turbo',
                    'gpt35turbo': 'gpt-3.5-turbo',
                    'gpt-3.5-turbo': 'gpt-3.5-turbo',
                    'gpt3.5': 'gpt-3.5-turbo',
                    'gpt-4o-mini': 'gpt-4o-mini',
                    'gpt4omini': 'gpt-4o-mini',
                }
                actual_model = model_name_map.get(normalized_model.replace(' ', '').replace('-', ''), normalized_model)
                print(f"[AI Test] OpenAI æ¨¡å‹åç¨±æ˜ å°„: {model_name} -> {actual_model}", file=sys.stderr)
                
                async with aiohttp.ClientSession() as session:
                    async with session.post(
                        'https://api.openai.com/v1/chat/completions',
                        headers={
                            'Authorization': f'Bearer {api_key}',
                            'Content-Type': 'application/json'
                        },
                        json={
                            "model": actual_model,
                            "messages": [{"role": "user", "content": "Hi"}],
                            "max_tokens": 5
                        },
                        timeout=aiohttp.ClientTimeout(total=15)
                    ) as resp:
                        print(f"[AI Test] OpenAI éŸ¿æ‡‰ç‹€æ…‹: {resp.status}", file=sys.stderr)
                        if resp.status == 200:
                            data = await resp.json()
                            content = data.get('choices', [{}])[0].get('message', {}).get('content', '')
                            is_connected = True
                            response_preview = f"OpenAI ({actual_model}) é€£æ¥æˆåŠŸ" + (f": {content[:30]}..." if content else "")
                        else:
                            data = await resp.json()
                            api_error = data.get('error', {})
                            error_code = api_error.get('code', '')
                            error_msg = api_error.get('message', f"HTTP {resp.status}")
                            
                            # æä¾›æ›´å‹å¥½çš„éŒ¯èª¤æç¤º
                            if resp.status == 401:
                                error_message = "API Key ç„¡æ•ˆæˆ–å·²éæœŸï¼Œè«‹åœ¨ OpenAI å¾Œå°ç¢ºèª Key ç‹€æ…‹"
                            elif resp.status == 429:
                                # 429 è¡¨ç¤ºé™æµï¼Œä½†æ¨¡å‹å’Œ Key éƒ½æ˜¯æœ‰æ•ˆçš„
                                is_connected = True
                                response_preview = f"OpenAI ({actual_model}) å¯ç”¨ï¼ˆç•¶å‰é™æµä¸­ï¼‰"
                                print(f"[AI Test] âœ“ OpenAI {actual_model} è¢«é™æµï¼Œä½†ç¢ºèªå¯ç”¨", file=sys.stderr)
                            elif resp.status == 403:
                                error_message = "API Key æ²’æœ‰æ¬Šé™ï¼Œå¯èƒ½éœ€è¦ä»˜è²»å¸³æˆ¶"
                            elif 'model' in error_msg.lower() and 'not found' in error_msg.lower():
                                error_message = f"æ¨¡å‹ {actual_model} ä¸å­˜åœ¨æˆ–æ‚¨çš„å¸³æˆ¶ç„¡æ¬Šä½¿ç”¨"
                            else:
                                error_message = error_msg
                            
                            if error_message:
                                print(f"[AI Test] OpenAI éŒ¯èª¤: {error_message} (åŸå§‹: {error_msg})", file=sys.stderr)
                            
            elif provider == 'claude':
                import aiohttp
                # è‡ªå‹•æ ¼å¼åŒ–æ¨¡å‹åç¨±
                normalized_model = model_name.lower().strip()
                claude_model_map = {
                    'claude': 'claude-3-5-sonnet-latest',
                    'claude3': 'claude-3-5-sonnet-latest',
                    'claude-3': 'claude-3-5-sonnet-latest',
                    'claude-3-opus': 'claude-3-opus-latest',
                    'claude3opus': 'claude-3-opus-latest',
                    'claude-3-sonnet': 'claude-3-5-sonnet-latest',
                    'claude3sonnet': 'claude-3-5-sonnet-latest',
                    'claude-3-haiku': 'claude-3-haiku-20240307',
                    'claude3haiku': 'claude-3-haiku-20240307',
                    'claude-3.5-sonnet': 'claude-3-5-sonnet-latest',
                    'claude-3-5-sonnet': 'claude-3-5-sonnet-latest',
                }
                actual_model = claude_model_map.get(normalized_model.replace(' ', '').replace('-', '').replace('.', ''), model_name)
                print(f"[AI Test] Claude æ¨¡å‹åç¨±æ˜ å°„: {model_name} -> {actual_model}", file=sys.stderr)
                
                async with aiohttp.ClientSession() as session:
                    async with session.post(
                        'https://api.anthropic.com/v1/messages',
                        headers={
                            'x-api-key': api_key,
                            'anthropic-version': '2023-06-01',
                            'Content-Type': 'application/json'
                        },
                        json={
                            "model": actual_model,
                            "max_tokens": 5,
                            "messages": [{"role": "user", "content": "Hi"}]
                        },
                        timeout=aiohttp.ClientTimeout(total=15)
                    ) as resp:
                        print(f"[AI Test] Claude éŸ¿æ‡‰ç‹€æ…‹: {resp.status}", file=sys.stderr)
                        if resp.status == 200:
                            is_connected = True
                            response_preview = "Claude é€£æ¥æˆåŠŸ"
                        else:
                            data = await resp.json()
                            error_message = data.get('error', {}).get('message', f"HTTP {resp.status}")
                            if 'authentication' in error_message.lower():
                                error_message = "API Key ç„¡æ•ˆ"
                            print(f"[AI Test] Claude éŒ¯èª¤: {error_message}", file=sys.stderr)
                            
            elif provider == 'gemini':
                import aiohttp
                # Gemini æ¨¡å‹åç¨±åˆ—è¡¨ï¼ˆå˜—è©¦å¤šå€‹è®Šé«”ï¼‰
                gemini_models_to_try = []
                normalized = model_name.lower().strip()
                
                # æ·»åŠ ç”¨æˆ¶è¼¸å…¥çš„æ¨¡å‹å
                gemini_models_to_try.append(model_name)
                
                # æ·»åŠ å¸¸è¦‹è®Šé«”
                if 'flash' in normalized:
                    gemini_models_to_try.extend([
                        'gemini-1.5-flash-latest',
                        'gemini-1.5-flash',
                        'gemini-1.5-flash-001',
                        'gemini-2.0-flash-exp'
                    ])
                elif 'pro' in normalized:
                    gemini_models_to_try.extend([
                        'gemini-1.5-pro-latest',
                        'gemini-1.5-pro',
                        'gemini-1.5-pro-001',
                        'gemini-pro'
                    ])
                else:
                    gemini_models_to_try.extend([
                        'gemini-1.5-flash-latest',
                        'gemini-1.5-pro-latest'
                    ])
                
                # å»é‡
                gemini_models_to_try = list(dict.fromkeys(gemini_models_to_try))
                print(f"[AI Test] Gemini å°‡å˜—è©¦æ¨¡å‹åˆ—è¡¨: {gemini_models_to_try}", file=sys.stderr)
                
                async with aiohttp.ClientSession() as session:
                    for try_model in gemini_models_to_try:
                        url = f'https://generativelanguage.googleapis.com/v1beta/models/{try_model}:generateContent?key={api_key}'
                        print(f"[AI Test] å˜—è©¦ Gemini æ¨¡å‹: {try_model}", file=sys.stderr)
                        try:
                            async with session.post(
                                url,
                                json={
                                    "contents": [{"role": "user", "parts": [{"text": "Hi"}]}],
                                    "generationConfig": {"maxOutputTokens": 10}
                                },
                                timeout=aiohttp.ClientTimeout(total=10)
                            ) as resp:
                                print(f"[AI Test] Gemini {try_model} éŸ¿æ‡‰ç‹€æ…‹: {resp.status}", file=sys.stderr)
                                if resp.status == 200:
                                    data = await resp.json()
                                    content = data.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '')
                                    is_connected = True
                                    response_preview = f"Gemini ({try_model}) é€£æ¥æˆåŠŸ" + (f": {content[:30]}..." if content else "")
                                    print(f"[AI Test] âœ“ Gemini é€£æ¥æˆåŠŸ: {try_model}", file=sys.stderr)
                                    break
                                elif resp.status == 400:
                                    data = await resp.json()
                                    err = data.get('error', {}).get('message', '')
                                    if 'API_KEY_INVALID' in err or 'API key' in err:
                                        error_message = "API Key ç„¡æ•ˆï¼Œè«‹æª¢æŸ¥ Google AI Studio ä¸­çš„ API Key"
                                        break
                                elif resp.status == 403:
                                    error_message = "API Key æ²’æœ‰æ¬Šé™ä½¿ç”¨ Gemini APIï¼Œè«‹åœ¨ Google AI Studio ä¸­å•Ÿç”¨"
                                    break
                                elif resp.status == 429:
                                    # 429 è¡¨ç¤ºé™æµï¼Œä½†æ¨¡å‹å­˜åœ¨ä¸”å¯ç”¨
                                    is_connected = True
                                    response_preview = f"Gemini ({try_model}) å¯ç”¨ï¼ˆç•¶å‰é™æµä¸­ï¼‰"
                                    print(f"[AI Test] âœ“ Gemini {try_model} è¢«é™æµï¼Œä½†ç¢ºèªå¯ç”¨", file=sys.stderr)
                                    break
                        except Exception as try_e:
                            print(f"[AI Test] Gemini {try_model} å˜—è©¦å¤±æ•—: {try_e}", file=sys.stderr)
                            continue
                    
                    if not is_connected and not error_message:
                        error_message = f"æ‰€æœ‰ Gemini æ¨¡å‹è®Šé«”éƒ½ç„¡æ³•é€£æ¥ï¼Œè«‹ç¢ºèª API Key æ­£ç¢ºä¸”å·²å•Ÿç”¨ Generative Language API"
            else:
                error_message = f"æœªçŸ¥ä¾›æ‡‰å•†: {provider}"
                
        except asyncio.TimeoutError:
            error_message = "é€£æ¥è¶…æ™‚ï¼Œè«‹æª¢æŸ¥ç¶²çµ¡é€£æ¥æˆ– API ç«¯é»æ˜¯å¦æ­£ç¢º"
        except Exception as test_error:
            error_str = str(test_error)
            error_type = type(test_error).__name__
            # ğŸ”§ å‹å¥½åŒ–å¸¸è¦‹éŒ¯èª¤ä¿¡æ¯
            if 'ClientConnectorError' in error_type or 'ConnectionRefused' in error_str or 'Cannot connect' in error_str:
                error_message = "ç„¡æ³•é€£æ¥åˆ° AI æœå‹™ï¼Œè«‹ç¢ºèªæœå‹™å·²å•Ÿå‹•ä¸”ç«¯é»æ­£ç¢º"
            elif 'Name or service not known' in error_str or 'getaddrinfo failed' in error_str:
                error_message = "ç„¡æ•ˆçš„ API ç«¯é»åœ°å€ï¼Œè«‹æª¢æŸ¥ URL æ ¼å¼"
            elif 'SSL' in error_str or 'certificate' in error_str.lower():
                error_message = "SSL/TLS è­‰æ›¸é©—è­‰å¤±æ•—ï¼Œå¯èƒ½éœ€è¦ä¿¡ä»»è‡ªç°½åè­‰æ›¸"
            elif 'ClientError' in error_type:
                error_message = f"ç¶²çµ¡è«‹æ±‚å¤±æ•—ï¼š{error_str[:50]}"
            else:
                error_message = f"æ¸¬è©¦å¤±æ•—ï¼š{error_str[:100]}"
        
        # æ›´æ–°æ•¸æ“šåº«ä¸­çš„é€£æ¥ç‹€æ…‹
        if model_id:
            await db.execute(
                "UPDATE ai_models SET is_connected = ?, last_tested_at = CURRENT_TIMESTAMP WHERE id = ?",
                (1 if is_connected else 0, model_id)
            )
        
        if is_connected:
            self.send_log(f"âœ… AI æ¨¡å‹é€£æ¥æˆåŠŸ: {model_name}" + (f" - {response_preview}" if response_preview else ""), "success")
        else:
            self.send_log(f"âŒ AI æ¨¡å‹é€£æ¥å¤±æ•—: {model_name} - {error_message}", "error")
        
        # ğŸ”§ P0+P2 å„ªåŒ–ï¼šåŒ…å«å»¶é²æ™‚é–“å’Œå¯ç”¨æ¨¡å‹åˆ—è¡¨
        self.send_event("ai-model-tested", {
            "success": True,
            "modelId": model_id,
            "isConnected": is_connected,
            "error": error_message,
            "responsePreview": response_preview,
            "modelName": model_name,
            "latencyMs": latency_ms if 'latency_ms' in dir() else None,
            "availableModels": available_models if 'available_models' in dir() else []
        })
        
    except Exception as e:
        import traceback
        print(f"[AI Test] æ¸¬è©¦éç¨‹ç•°å¸¸: {traceback.format_exc()}", file=__import__('sys').stderr)
        self.send_event("ai-model-tested", {"success": False, "error": str(e)})


async def handle_set_default_ai_model(self, payload: Dict[str, Any]):
    """è¨­ç½®é»˜èª AI æ¨¡å‹"""
    try:
        model_id = payload.get('id')
        if not model_id:
            self.send_event("ai-model-default-set", {"success": False, "error": "ç¼ºå°‘æ¨¡å‹ ID"})
            return
        
        # å…ˆå–æ¶ˆæ‰€æœ‰é»˜èª
        await db.execute("UPDATE ai_models SET is_default = 0")
        # è¨­ç½®æ–°é»˜èª
        await db.execute("UPDATE ai_models SET is_default = 1 WHERE id = ?", (model_id,))
        
        self.send_log(f"âœ… å·²è¨­ç½®é»˜èª AI æ¨¡å‹: ID={model_id}", "success")
        self.send_event("ai-model-default-set", {"success": True, "modelId": model_id})
        await self.handle_get_ai_models()
        
    except Exception as e:
        self.send_event("ai-model-default-set", {"success": False, "error": str(e)})


async def handle_save_model_usage(self, payload: Dict[str, Any]):
    """ä¿å­˜æ¨¡å‹ç”¨é€”åˆ†é…"""
    try:
        intent_recognition = payload.get('intentRecognition', '')
        daily_chat = payload.get('dailyChat', '')
        multi_role_script = payload.get('multiRoleScript', '')
        
        # ä¿å­˜åˆ° ai_settings è¡¨
        await db.execute("""
            INSERT INTO ai_settings (key, value) VALUES ('model_usage', ?)
            ON CONFLICT(key) DO UPDATE SET value = excluded.value, updated_at = CURRENT_TIMESTAMP
        """, (json.dumps({
            'intentRecognition': intent_recognition,
            'dailyChat': daily_chat,
            'multiRoleScript': multi_role_script
        }),))
        
        print(f"[AI] æ¨¡å‹ç”¨é€”åˆ†é…å·²ä¿å­˜: intent={intent_recognition}, chat={daily_chat}, multi={multi_role_script}", file=sys.stderr)
        self.send_event("model-usage-saved", {"success": True})
        
    except Exception as e:
        print(f"[AI] ä¿å­˜æ¨¡å‹ç”¨é€”åˆ†é…å¤±æ•—: {e}", file=sys.stderr)
        self.send_event("model-usage-saved", {"success": False, "error": str(e)})


async def handle_get_model_usage(self, data=None):
    """ç²å–æ¨¡å‹ç”¨é€”åˆ†é…"""
    try:
        row = await db.fetch_one(
            "SELECT value FROM ai_settings WHERE key = 'model_usage'"
        )
        
        if row and row.get('value'):
            usage = json.loads(row['value'])
        else:
            usage = {
                'intentRecognition': '',
                'dailyChat': '',
                'multiRoleScript': ''
            }
        
        print(f"[AI] æ¨¡å‹ç”¨é€”åˆ†é…å·²åŠ è¼‰: {usage}", file=sys.stderr)
        self.send_event("model-usage-loaded", {"success": True, "usage": usage})
        
    except Exception as e:
        print(f"[AI] ç²å–æ¨¡å‹ç”¨é€”åˆ†é…å¤±æ•—: {e}", file=sys.stderr)
        self.send_event("model-usage-loaded", {"success": False, "error": str(e)})

