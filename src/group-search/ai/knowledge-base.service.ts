/**
 * TG-AIæ™ºæ§ç‹ çŸ¥è­˜åº«æœå‹™
 * Knowledge Base Service v1.0
 * 
 * ğŸ’¡ è¨­è¨ˆæ€è€ƒï¼š
 * 1. æ–‡æª”åˆ†å¡Š - æ™ºèƒ½åˆ†å‰²é•·æ–‡æª”ç‚ºå¯æª¢ç´¢ç‰‡æ®µ
 * 2. å‘é‡åµŒå…¥ - ä½¿ç”¨æœ¬åœ°æˆ–é ç¨‹æ¨¡å‹ç”ŸæˆåµŒå…¥
 * 3. æ··åˆæœç´¢ - é—œéµè© + èªç¾©é›™é‡æœç´¢
 * 4. ä¸Šä¸‹æ–‡å¢å¼· - æª¢ç´¢çµæœå¢å¼· AI å›ç­”
 * 5. å¢é‡æ›´æ–° - æ”¯æŒéƒ¨åˆ†æ›´æ–°ï¼Œç„¡éœ€å…¨é‡é‡å»º
 */

import { Injectable, signal, computed, inject } from '@angular/core';
import { IndexedDBService } from '../performance/indexed-db.service';
import { WorkerPoolService } from '../performance/worker-pool.service';

// ============ é¡å‹å®šç¾© ============

export interface KnowledgeDocument {
  id: string;
  title: string;
  content: string;
  type: 'text' | 'markdown' | 'faq' | 'product' | 'policy';
  metadata: {
    source?: string;
    author?: string;
    createdAt: number;
    updatedAt: number;
    tags?: string[];
    language?: string;
  };
  chunks: DocumentChunk[];
  status: 'pending' | 'processing' | 'indexed' | 'error';
}

export interface DocumentChunk {
  id: string;
  documentId: string;
  content: string;
  index: number;
  startPosition: number;
  endPosition: number;
  embedding?: number[];
  metadata: {
    section?: string;
    heading?: string;
  };
}

export interface SearchResult {
  chunk: DocumentChunk;
  document: KnowledgeDocument;
  score: number;
  matchType: 'semantic' | 'keyword' | 'hybrid';
  highlights: string[];
}

export interface KnowledgeBaseConfig {
  chunkSize: number;           // åˆ†å¡Šå¤§å°ï¼ˆå­—ç¬¦æ•¸ï¼‰
  chunkOverlap: number;        // åˆ†å¡Šé‡ç–Š
  maxResults: number;          // æœ€å¤§çµæœæ•¸
  minScore: number;            // æœ€å°ç›¸é—œåº¦åˆ†æ•¸
  embeddingModel: 'local' | 'openai' | 'custom';
  hybridWeight: number;        // æ··åˆæœç´¢æ¬Šé‡ï¼ˆ0-1ï¼Œ1=ç´”èªç¾©ï¼‰
}

export interface KnowledgeStats {
  totalDocuments: number;
  totalChunks: number;
  totalTokens: number;
  lastUpdated: number;
  indexSize: number;
}

// ============ é»˜èªé…ç½® ============

const DEFAULT_CONFIG: KnowledgeBaseConfig = {
  chunkSize: 500,
  chunkOverlap: 50,
  maxResults: 5,
  minScore: 0.3,
  embeddingModel: 'local',
  hybridWeight: 0.7
};

// ============ æœ¬åœ°åµŒå…¥è¨ˆç®— ============

/**
 * ğŸ’¡ æ€è€ƒï¼šä½¿ç”¨ TF-IDF ä½œç‚ºæœ¬åœ°åµŒå…¥æ–¹æ¡ˆ
 * å„ªé»ï¼šç„¡éœ€ API èª¿ç”¨ï¼Œéš±ç§å®‰å…¨ï¼Œé›¢ç·šå¯ç”¨
 * ç¼ºé»ï¼šèªç¾©ç†è§£ä¸å¦‚æ·±åº¦å­¸ç¿’æ¨¡å‹
 * æŠ˜ä¸­ï¼šä½¿ç”¨æ··åˆæœç´¢ï¼ˆTF-IDF + é—œéµè©ï¼‰æé«˜æº–ç¢ºæ€§
 */
class LocalEmbedding {
  private vocabulary = new Map<string, number>();
  private idf = new Map<string, number>();
  private documentCount = 0;
  
  /**
   * æ§‹å»ºè©å½™è¡¨
   */
  buildVocabulary(documents: string[]): void {
    const docFreq = new Map<string, number>();
    
    this.documentCount = documents.length;
    
    for (const doc of documents) {
      const terms = this.tokenize(doc);
      const uniqueTerms = new Set(terms);
      
      for (const term of uniqueTerms) {
        docFreq.set(term, (docFreq.get(term) || 0) + 1);
      }
      
      for (const term of terms) {
        if (!this.vocabulary.has(term)) {
          this.vocabulary.set(term, this.vocabulary.size);
        }
      }
    }
    
    // è¨ˆç®— IDF
    for (const [term, freq] of docFreq) {
      this.idf.set(term, Math.log((this.documentCount + 1) / (freq + 1)) + 1);
    }
  }
  
  /**
   * è¨ˆç®—æ–‡æœ¬çš„ TF-IDF å‘é‡
   */
  embed(text: string): number[] {
    const terms = this.tokenize(text);
    const tf = new Map<string, number>();
    
    // è¨ˆç®— TF
    for (const term of terms) {
      tf.set(term, (tf.get(term) || 0) + 1);
    }
    
    // æ­¸ä¸€åŒ– TF
    const maxTf = Math.max(...tf.values());
    
    // ç”Ÿæˆå‘é‡
    const vector = new Array(this.vocabulary.size).fill(0);
    
    for (const [term, freq] of tf) {
      const idx = this.vocabulary.get(term);
      if (idx !== undefined) {
        const normalizedTf = freq / maxTf;
        const idf = this.idf.get(term) || 1;
        vector[idx] = normalizedTf * idf;
      }
    }
    
    // L2 æ­¸ä¸€åŒ–
    const norm = Math.sqrt(vector.reduce((sum, v) => sum + v * v, 0));
    if (norm > 0) {
      for (let i = 0; i < vector.length; i++) {
        vector[i] /= norm;
      }
    }
    
    return vector;
  }
  
  /**
   * è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
   */
  cosineSimilarity(a: number[], b: number[]): number {
    if (a.length !== b.length) return 0;
    
    let dot = 0;
    for (let i = 0; i < a.length; i++) {
      dot += a[i] * b[i];
    }
    
    return dot; // å·²ç¶“ L2 æ­¸ä¸€åŒ–ï¼Œç›´æ¥è¿”å›é»ç©
  }
  
  /**
   * åˆ†è©ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
   */
  private tokenize(text: string): string[] {
    // ä¸­æ–‡åˆ†è© + è‹±æ–‡åˆ†è©
    const normalized = text.toLowerCase()
      .replace(/[^\u4e00-\u9fa5a-z0-9\s]/g, ' ')
      .trim();
    
    const tokens: string[] = [];
    
    // è™•ç†ä¸­æ–‡ï¼ˆæŒ‰å­—åˆ‡åˆ†ï¼Œä¸¦æå– n-gramï¼‰
    const chineseRegex = /[\u4e00-\u9fa5]+/g;
    let match;
    while ((match = chineseRegex.exec(normalized)) !== null) {
      const chinese = match[0];
      // å–®å­—
      for (const char of chinese) {
        tokens.push(char);
      }
      // äºŒå­—è©
      for (let i = 0; i < chinese.length - 1; i++) {
        tokens.push(chinese.substr(i, 2));
      }
    }
    
    // è™•ç†è‹±æ–‡
    const englishRegex = /[a-z0-9]+/g;
    while ((match = englishRegex.exec(normalized)) !== null) {
      if (match[0].length >= 2) {
        tokens.push(match[0]);
      }
    }
    
    return tokens;
  }
  
  /**
   * ç²å–è©å½™è¡¨å¤§å°
   */
  getVocabularySize(): number {
    return this.vocabulary.size;
  }
}

@Injectable({
  providedIn: 'root'
})
export class KnowledgeBaseService {
  private db = inject(IndexedDBService);
  private workerPool = inject(WorkerPoolService);
  
  private config: KnowledgeBaseConfig;
  private localEmbedding = new LocalEmbedding();
  private isInitialized = false;
  
  // æ–‡æª”ç·©å­˜
  private documents = new Map<string, KnowledgeDocument>();
  
  // ç‹€æ…‹
  private _stats = signal<KnowledgeStats>({
    totalDocuments: 0,
    totalChunks: 0,
    totalTokens: 0,
    lastUpdated: 0,
    indexSize: 0
  });
  stats = computed(() => this._stats());
  
  private _isProcessing = signal(false);
  isProcessing = computed(() => this._isProcessing());
  
  constructor() {
    this.config = { ...DEFAULT_CONFIG };
    this.initialize();
  }
  
  // ============ åˆå§‹åŒ– ============
  
  private async initialize(): Promise<void> {
    try {
      // è¼‰å…¥å·²ç´¢å¼•çš„æ–‡æª”
      await this.loadDocuments();
      
      // æ§‹å»ºè©å½™è¡¨
      if (this.documents.size > 0) {
        const allChunks = [...this.documents.values()]
          .flatMap(doc => doc.chunks.map(c => c.content));
        this.localEmbedding.buildVocabulary(allChunks);
      }
      
      this.isInitialized = true;
      console.log('[KnowledgeBase] Initialized with', this.documents.size, 'documents');
      
    } catch (error) {
      console.error('[KnowledgeBase] Initialization failed:', error);
    }
  }
  
  private async loadDocuments(): Promise<void> {
    const stored = await this.db.getAll<KnowledgeDocument>('knowledgeBase');
    
    for (const doc of stored) {
      this.documents.set(doc.id, doc);
    }
    
    this.updateStats();
  }
  
  // ============ æ–‡æª”ç®¡ç† ============
  
  /**
   * æ·»åŠ æ–‡æª”åˆ°çŸ¥è­˜åº«
   */
  async addDocument(
    title: string,
    content: string,
    type: KnowledgeDocument['type'] = 'text',
    metadata?: Partial<KnowledgeDocument['metadata']>
  ): Promise<KnowledgeDocument> {
    this._isProcessing.set(true);
    
    try {
      const doc: KnowledgeDocument = {
        id: `doc_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        title,
        content,
        type,
        metadata: {
          createdAt: Date.now(),
          updatedAt: Date.now(),
          ...metadata
        },
        chunks: [],
        status: 'pending'
      };
      
      // åˆ†å¡Šè™•ç†
      doc.chunks = await this.chunkDocument(doc);
      
      // ç”ŸæˆåµŒå…¥
      await this.embedChunks(doc.chunks);
      
      // æ›´æ–°è©å½™è¡¨
      this.localEmbedding.buildVocabulary([
        ...this.getAllChunkContents(),
        ...doc.chunks.map(c => c.content)
      ]);
      
      doc.status = 'indexed';
      
      // ä¿å­˜
      this.documents.set(doc.id, doc);
      await this.db.put('knowledgeBase', doc);
      
      this.updateStats();
      
      return doc;
      
    } finally {
      this._isProcessing.set(false);
    }
  }
  
  /**
   * æ‰¹é‡æ·»åŠ æ–‡æª”
   */
  async addDocuments(
    documents: Array<{
      title: string;
      content: string;
      type?: KnowledgeDocument['type'];
      metadata?: Partial<KnowledgeDocument['metadata']>;
    }>
  ): Promise<KnowledgeDocument[]> {
    this._isProcessing.set(true);
    
    try {
      const results: KnowledgeDocument[] = [];
      
      for (const item of documents) {
        const doc = await this.addDocument(
          item.title,
          item.content,
          item.type || 'text',
          item.metadata
        );
        results.push(doc);
      }
      
      return results;
      
    } finally {
      this._isProcessing.set(false);
    }
  }
  
  /**
   * æ›´æ–°æ–‡æª”
   */
  async updateDocument(
    id: string,
    updates: {
      title?: string;
      content?: string;
      metadata?: Partial<KnowledgeDocument['metadata']>;
    }
  ): Promise<KnowledgeDocument | null> {
    const doc = this.documents.get(id);
    if (!doc) return null;
    
    this._isProcessing.set(true);
    
    try {
      if (updates.title) doc.title = updates.title;
      if (updates.metadata) {
        doc.metadata = { ...doc.metadata, ...updates.metadata };
      }
      
      // å¦‚æœå…§å®¹æ›´æ–°ï¼Œéœ€è¦é‡æ–°åˆ†å¡Šå’ŒåµŒå…¥
      if (updates.content) {
        doc.content = updates.content;
        doc.chunks = await this.chunkDocument(doc);
        await this.embedChunks(doc.chunks);
        
        // é‡å»ºè©å½™è¡¨
        this.localEmbedding.buildVocabulary(this.getAllChunkContents());
      }
      
      doc.metadata.updatedAt = Date.now();
      
      await this.db.put('knowledgeBase', doc);
      this.updateStats();
      
      return doc;
      
    } finally {
      this._isProcessing.set(false);
    }
  }
  
  /**
   * åˆªé™¤æ–‡æª”
   */
  async deleteDocument(id: string): Promise<boolean> {
    if (!this.documents.has(id)) return false;
    
    this.documents.delete(id);
    await this.db.delete('knowledgeBase', id);
    
    // é‡å»ºè©å½™è¡¨
    this.localEmbedding.buildVocabulary(this.getAllChunkContents());
    
    this.updateStats();
    return true;
  }
  
  /**
   * ç²å–æ–‡æª”
   */
  getDocument(id: string): KnowledgeDocument | undefined {
    return this.documents.get(id);
  }
  
  /**
   * ç²å–æ‰€æœ‰æ–‡æª”
   */
  getAllDocuments(): KnowledgeDocument[] {
    return [...this.documents.values()];
  }
  
  // ============ æ–‡æª”åˆ†å¡Š ============
  
  /**
   * æ™ºèƒ½åˆ†å¡Š
   * 
   * ğŸ’¡ æ€è€ƒï¼šä½¿ç”¨å¤šç¨®ç­–ç•¥ç¢ºä¿åˆ†å¡Šè³ªé‡
   * 1. æŒ‰æ®µè½åˆ†å‰²
   * 2. æŒ‰æ¨™é¡Œåˆ†å‰²ï¼ˆMarkdownï¼‰
   * 3. æŒ‰å›ºå®šå¤§å°åˆ†å‰²ï¼ˆå¸¶é‡ç–Šï¼‰
   * 4. ä¿æŒèªç¾©å®Œæ•´æ€§
   */
  private async chunkDocument(doc: KnowledgeDocument): Promise<DocumentChunk[]> {
    const chunks: DocumentChunk[] = [];
    let content = doc.content;
    
    // æ ¹æ“šæ–‡æª”é¡å‹é¸æ“‡åˆ†å¡Šç­–ç•¥
    switch (doc.type) {
      case 'markdown':
        return this.chunkMarkdown(doc);
      case 'faq':
        return this.chunkFAQ(doc);
      default:
        return this.chunkBySize(doc);
    }
  }
  
  /**
   * Markdown åˆ†å¡Šï¼ˆæŒ‰æ¨™é¡Œï¼‰
   */
  private chunkMarkdown(doc: KnowledgeDocument): DocumentChunk[] {
    const chunks: DocumentChunk[] = [];
    const lines = doc.content.split('\n');
    
    let currentSection = '';
    let currentHeading = '';
    let currentContent = '';
    let startPosition = 0;
    
    for (const line of lines) {
      // æª¢æ¸¬æ¨™é¡Œ
      const headingMatch = line.match(/^(#{1,6})\s+(.+)$/);
      
      if (headingMatch) {
        // ä¿å­˜å‰ä¸€å€‹éƒ¨åˆ†
        if (currentContent.trim()) {
          chunks.push(this.createChunk(
            doc.id,
            currentContent.trim(),
            chunks.length,
            startPosition,
            startPosition + currentContent.length,
            { section: currentSection, heading: currentHeading }
          ));
        }
        
        currentHeading = headingMatch[2];
        currentSection = headingMatch[1].length <= 2 ? currentHeading : currentSection;
        currentContent = '';
        startPosition = doc.content.indexOf(line, startPosition);
      } else {
        currentContent += line + '\n';
      }
    }
    
    // ä¿å­˜æœ€å¾Œä¸€å€‹éƒ¨åˆ†
    if (currentContent.trim()) {
      chunks.push(this.createChunk(
        doc.id,
        currentContent.trim(),
        chunks.length,
        startPosition,
        doc.content.length,
        { section: currentSection, heading: currentHeading }
      ));
    }
    
    // å¦‚æœæŸäº›å¡Šå¤ªå¤§ï¼Œé€²ä¸€æ­¥åˆ†å‰²
    return chunks.flatMap(chunk => {
      if (chunk.content.length > this.config.chunkSize * 2) {
        return this.splitLargeChunk(chunk);
      }
      return [chunk];
    });
  }
  
  /**
   * FAQ åˆ†å¡Šï¼ˆæŒ‰å•ç­”å°ï¼‰
   */
  private chunkFAQ(doc: KnowledgeDocument): DocumentChunk[] {
    const chunks: DocumentChunk[] = [];
    
    // åŒ¹é… Q: A: æˆ– å•: ç­”: æ ¼å¼
    const qaRegex = /(?:Q:|å•:|é—®:)\s*(.+?)[\n\r]+(?:A:|ç­”:)\s*(.+?)(?=(?:Q:|å•:|é—®:)|$)/gis;
    let match;
    let index = 0;
    
    while ((match = qaRegex.exec(doc.content)) !== null) {
      const question = match[1].trim();
      const answer = match[2].trim();
      const content = `å•ï¼š${question}\nç­”ï¼š${answer}`;
      
      chunks.push(this.createChunk(
        doc.id,
        content,
        index++,
        match.index,
        match.index + match[0].length,
        { heading: question }
      ));
    }
    
    // å¦‚æœæ²’æœ‰åŒ¹é…åˆ° QA æ ¼å¼ï¼Œä½¿ç”¨æ™®é€šåˆ†å¡Š
    if (chunks.length === 0) {
      return this.chunkBySize(doc);
    }
    
    return chunks;
  }
  
  /**
   * æŒ‰å¤§å°åˆ†å¡Šï¼ˆå¸¶é‡ç–Šï¼‰
   */
  private chunkBySize(doc: KnowledgeDocument): DocumentChunk[] {
    const chunks: DocumentChunk[] = [];
    const content = doc.content;
    const { chunkSize, chunkOverlap } = this.config;
    
    let start = 0;
    let index = 0;
    
    while (start < content.length) {
      // å˜—è©¦åœ¨å¥å­é‚Šç•Œè™•åˆ†å‰²
      let end = Math.min(start + chunkSize, content.length);
      
      if (end < content.length) {
        // å‘å¾Œæ‰¾å¥å­çµæŸ
        const sentenceEnd = content.slice(start, end + 100)
          .search(/[ã€‚ï¼ï¼Ÿ.!?]\s*(?=[^ã€‚ï¼ï¼Ÿ.!?]|$)/);
        
        if (sentenceEnd > 0 && sentenceEnd < chunkSize + 100) {
          end = start + sentenceEnd + 1;
        }
      }
      
      const chunkContent = content.slice(start, end).trim();
      
      if (chunkContent) {
        chunks.push(this.createChunk(
          doc.id,
          chunkContent,
          index++,
          start,
          end,
          {}
        ));
      }
      
      // ä¸‹ä¸€å¡Šé–‹å§‹ä½ç½®ï¼ˆå¸¶é‡ç–Šï¼‰
      start = end - chunkOverlap;
      if (start <= chunks[chunks.length - 1]?.startPosition) {
        start = end;
      }
    }
    
    return chunks;
  }
  
  /**
   * åˆ†å‰²éå¤§çš„å¡Š
   */
  private splitLargeChunk(chunk: DocumentChunk): DocumentChunk[] {
    const result: DocumentChunk[] = [];
    const { chunkSize, chunkOverlap } = this.config;
    
    let start = 0;
    let index = 0;
    
    while (start < chunk.content.length) {
      const end = Math.min(start + chunkSize, chunk.content.length);
      const content = chunk.content.slice(start, end).trim();
      
      if (content) {
        result.push({
          ...chunk,
          id: `${chunk.id}_${index}`,
          content,
          index: chunk.index + index * 0.1,
          startPosition: chunk.startPosition + start,
          endPosition: chunk.startPosition + end
        });
      }
      
      start = end - chunkOverlap;
      index++;
    }
    
    return result;
  }
  
  private createChunk(
    documentId: string,
    content: string,
    index: number,
    start: number,
    end: number,
    metadata: DocumentChunk['metadata']
  ): DocumentChunk {
    return {
      id: `chunk_${documentId}_${index}`,
      documentId,
      content,
      index,
      startPosition: start,
      endPosition: end,
      metadata
    };
  }
  
  // ============ åµŒå…¥è¨ˆç®— ============
  
  /**
   * ç‚ºåˆ†å¡Šç”ŸæˆåµŒå…¥å‘é‡
   */
  private async embedChunks(chunks: DocumentChunk[]): Promise<void> {
    for (const chunk of chunks) {
      switch (this.config.embeddingModel) {
        case 'local':
          chunk.embedding = this.localEmbedding.embed(chunk.content);
          break;
        case 'openai':
          // TODO: èª¿ç”¨ OpenAI API
          chunk.embedding = this.localEmbedding.embed(chunk.content);
          break;
        default:
          chunk.embedding = this.localEmbedding.embed(chunk.content);
      }
    }
  }
  
  // ============ æœç´¢ ============
  
  /**
   * æœç´¢çŸ¥è­˜åº«
   * 
   * ğŸ’¡ ä½¿ç”¨æ··åˆæœç´¢ç­–ç•¥
   * 1. èªç¾©æœç´¢ï¼ˆåŸºæ–¼åµŒå…¥å‘é‡ï¼‰
   * 2. é—œéµè©æœç´¢ï¼ˆåŸºæ–¼ BM25ï¼‰
   * 3. èåˆæ’åºï¼ˆåŠ æ¬Šçµ„åˆï¼‰
   */
  async search(query: string, options?: {
    maxResults?: number;
    minScore?: number;
    documentTypes?: KnowledgeDocument['type'][];
    documentIds?: string[];
  }): Promise<SearchResult[]> {
    if (!this.isInitialized) {
      await this.initialize();
    }
    
    const maxResults = options?.maxResults ?? this.config.maxResults;
    const minScore = options?.minScore ?? this.config.minScore;
    
    // ç²å–æ‰€æœ‰å¯æœç´¢çš„å¡Š
    let chunks = this.getAllChunks();
    
    // æŒ‰æ–‡æª”é¡å‹éæ¿¾
    if (options?.documentTypes?.length) {
      const docIds = new Set(
        [...this.documents.values()]
          .filter(d => options.documentTypes!.includes(d.type))
          .map(d => d.id)
      );
      chunks = chunks.filter(c => docIds.has(c.documentId));
    }
    
    // æŒ‰æ–‡æª” ID éæ¿¾
    if (options?.documentIds?.length) {
      const docIds = new Set(options.documentIds);
      chunks = chunks.filter(c => docIds.has(c.documentId));
    }
    
    // èªç¾©æœç´¢
    const queryEmbedding = this.localEmbedding.embed(query);
    const semanticScores = chunks.map(chunk => ({
      chunk,
      score: chunk.embedding 
        ? this.localEmbedding.cosineSimilarity(queryEmbedding, chunk.embedding)
        : 0
    }));
    
    // é—œéµè©æœç´¢
    const keywordScores = this.keywordSearch(query, chunks);
    
    // èåˆåˆ†æ•¸
    const { hybridWeight } = this.config;
    const fusedResults = chunks.map((chunk, i) => {
      const semanticScore = semanticScores[i].score;
      const keywordScore = keywordScores.get(chunk.id) || 0;
      const fusedScore = hybridWeight * semanticScore + (1 - hybridWeight) * keywordScore;
      
      return {
        chunk,
        document: this.documents.get(chunk.documentId)!,
        score: fusedScore,
        matchType: this.getMatchType(semanticScore, keywordScore) as SearchResult['matchType'],
        highlights: this.extractHighlights(query, chunk.content)
      };
    });
    
    // æ’åºå’Œéæ¿¾
    return fusedResults
      .filter(r => r.score >= minScore)
      .sort((a, b) => b.score - a.score)
      .slice(0, maxResults);
  }
  
  /**
   * é—œéµè©æœç´¢ï¼ˆBM25 é¢¨æ ¼ï¼‰
   */
  private keywordSearch(
    query: string,
    chunks: DocumentChunk[]
  ): Map<string, number> {
    const scores = new Map<string, number>();
    const queryTerms = query.toLowerCase().split(/\s+/);
    
    const avgLength = chunks.reduce((sum, c) => sum + c.content.length, 0) / chunks.length;
    const k1 = 1.5;
    const b = 0.75;
    
    for (const chunk of chunks) {
      let score = 0;
      const content = chunk.content.toLowerCase();
      const docLength = content.length;
      
      for (const term of queryTerms) {
        if (term.length < 2) continue;
        
        // è¨ˆç®—è©é »
        const regex = new RegExp(term, 'gi');
        const matches = content.match(regex);
        const tf = matches ? matches.length : 0;
        
        if (tf > 0) {
          // BM25 å…¬å¼
          const idf = Math.log((chunks.length - this.getDocFreq(term, chunks) + 0.5) / 
                              (this.getDocFreq(term, chunks) + 0.5) + 1);
          const tfNorm = (tf * (k1 + 1)) / 
                        (tf + k1 * (1 - b + b * docLength / avgLength));
          score += idf * tfNorm;
        }
      }
      
      // æ­¸ä¸€åŒ–
      scores.set(chunk.id, Math.min(1, score / queryTerms.length));
    }
    
    return scores;
  }
  
  private getDocFreq(term: string, chunks: DocumentChunk[]): number {
    return chunks.filter(c => 
      c.content.toLowerCase().includes(term.toLowerCase())
    ).length;
  }
  
  private getMatchType(semantic: number, keyword: number): string {
    if (semantic > keyword * 1.5) return 'semantic';
    if (keyword > semantic * 1.5) return 'keyword';
    return 'hybrid';
  }
  
  /**
   * æå–é«˜äº®ç‰‡æ®µ
   */
  private extractHighlights(query: string, content: string): string[] {
    const highlights: string[] = [];
    const terms = query.toLowerCase().split(/\s+/).filter(t => t.length >= 2);
    
    for (const term of terms) {
      const regex = new RegExp(`(.{0,30})(${term})(.{0,30})`, 'gi');
      let match;
      
      while ((match = regex.exec(content)) !== null && highlights.length < 3) {
        highlights.push(`...${match[1]}ã€${match[2]}ã€‘${match[3]}...`);
      }
    }
    
    return highlights;
  }
  
  // ============ ä¸Šä¸‹æ–‡å¢å¼· ============
  
  /**
   * ç²å–å›ç­”ä¸Šä¸‹æ–‡
   * 
   * ğŸ’¡ ç‚º AI å›ç­”æä¾›ç›¸é—œçŸ¥è­˜ä¸Šä¸‹æ–‡
   */
  async getContext(query: string, maxTokens = 2000): Promise<string> {
    const results = await this.search(query, { maxResults: 5 });
    
    if (results.length === 0) {
      return '';
    }
    
    let context = 'ä»¥ä¸‹æ˜¯ç›¸é—œçš„çŸ¥è­˜åº«å…§å®¹ï¼š\n\n';
    let currentTokens = 0;
    
    for (const result of results) {
      const chunk = result.chunk;
      const doc = result.document;
      const estimatedTokens = chunk.content.length / 2; // ä¼°ç®— token æ•¸
      
      if (currentTokens + estimatedTokens > maxTokens) break;
      
      context += `ã€ä¾†æºï¼š${doc.title}ã€‘\n`;
      context += chunk.content + '\n\n';
      currentTokens += estimatedTokens;
    }
    
    return context;
  }
  
  /**
   * å¢å¼·å•é¡Œå›ç­”
   */
  async enhanceAnswer(
    question: string,
    baseAnswer: string
  ): Promise<{ enhanced: string; sources: SearchResult[] }> {
    const results = await this.search(question, { maxResults: 3 });
    
    if (results.length === 0) {
      return { enhanced: baseAnswer, sources: [] };
    }
    
    // æ§‹å»ºå¢å¼·å›ç­”
    let enhanced = baseAnswer;
    
    // æ·»åŠ ä¾†æºå¼•ç”¨
    if (results.length > 0) {
      enhanced += '\n\nğŸ“š ç›¸é—œåƒè€ƒï¼š\n';
      for (let i = 0; i < Math.min(3, results.length); i++) {
        const r = results[i];
        enhanced += `${i + 1}. ${r.document.title}`;
        if (r.chunk.metadata.heading) {
          enhanced += ` - ${r.chunk.metadata.heading}`;
        }
        enhanced += '\n';
      }
    }
    
    return { enhanced, sources: results };
  }
  
  // ============ è¼”åŠ©æ–¹æ³• ============
  
  private getAllChunks(): DocumentChunk[] {
    return [...this.documents.values()].flatMap(doc => doc.chunks);
  }
  
  private getAllChunkContents(): string[] {
    return this.getAllChunks().map(c => c.content);
  }
  
  private updateStats(): void {
    const allChunks = this.getAllChunks();
    const totalTokens = allChunks.reduce((sum, c) => sum + c.content.length / 2, 0);
    
    this._stats.set({
      totalDocuments: this.documents.size,
      totalChunks: allChunks.length,
      totalTokens: Math.round(totalTokens),
      lastUpdated: Date.now(),
      indexSize: this.localEmbedding.getVocabularySize()
    });
  }
  
  /**
   * å°å‡ºçŸ¥è­˜åº«
   */
  async export(): Promise<string> {
    const data = {
      version: '1.0',
      exportedAt: Date.now(),
      documents: [...this.documents.values()]
    };
    return JSON.stringify(data, null, 2);
  }
  
  /**
   * å°å…¥çŸ¥è­˜åº«
   */
  async import(jsonData: string): Promise<number> {
    const data = JSON.parse(jsonData);
    let imported = 0;
    
    for (const doc of data.documents) {
      // é‡æ–°ç”ŸæˆåµŒå…¥
      await this.embedChunks(doc.chunks);
      this.documents.set(doc.id, doc);
      await this.db.put('knowledgeBase', doc);
      imported++;
    }
    
    // é‡å»ºè©å½™è¡¨
    this.localEmbedding.buildVocabulary(this.getAllChunkContents());
    this.updateStats();
    
    return imported;
  }
  
  /**
   * æ¸…ç©ºçŸ¥è­˜åº«
   */
  async clear(): Promise<void> {
    this.documents.clear();
    await this.db.clear('knowledgeBase');
    this.updateStats();
  }
}
